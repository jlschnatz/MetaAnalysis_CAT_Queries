TY  - JOUR
T1  - Lessons Learned about the Application of Adaptive Testing in Several First-Year University Courses
AN  - 2699690168; EJ1340821
AB  - The adoption of computerised adaptive testing (CAT) instead of classical testing (FIT) raises questions from both teachers' and students' perspectives. The scientific literature shows that teachers using CAT instead of FIT should experience shorter times to complete the assessment and obtain more precise evaluations. As for the students, adaptive testing seems to increase their engagement, whereas the impossibility to revise the already given questions is usually seen as a detrimental characteristic. In such a context, the paper reports on a study concerning the aforementioned points. The outcomes seem almost all inline with the literature: no particular usability issues were detected, CAT is faster than FIT, and CAT does not seem more engaging than FIT. All these findings are reported in the conclusions as a list of suggestions to teachers interested in switching from FIT to CAT.
JF  - International Journal of Learning Technology
AU  - Angelone, Anna Maria
AU  - Galassi, Alessandra
AU  - Vittorini, Pierpaolo
Y1  - 2022
PY  - 2022
DA  - 2022
SP  - 3
EP  - 26
PB  - Inderscience Publishers
VL  - 17
IS  - 1
SN  - 1477-8386, 1477-8386
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Higher Education
KW  - Postsecondary Education
KW  - Teacher Attitudes
KW  - Learner Engagement
KW  - Educational Change
KW  - Student Evaluation
KW  - Computer Software
KW  - Student Attitudes
KW  - Grades (Scholastic)
KW  - Adaptive Testing
KW  - College Freshmen
KW  - Computer Assisted Testing
KW  - College Faculty
KW  - Evaluation Methods
KW  - Usability
UR  - https://www.proquest.com/scholarly-journals/lessons-learned-about-application-adaptive/docview/2699690168/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Lessons+Learned+about+the+Application+of+Adaptive+Testing+in+Several+First-Year+University+Courses&title=International+Journal+of+Learning+Technology&issn=14778386&date=2022-01-01&volume=17&issue=1&spage=3&au=Angelone%2C+Anna+Maria%3BGalassi%2C+Alessandra%3BVittorini%2C+Pierpaolo&isbn=&jtitle=International+Journal+of+Learning+Technology&btitle=&rft_id=info:eric/EJ1340821&rft_id=info:doi/10.1504%2FIJLT.2022.123696
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2022-10-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 1798ER1 1829ER1 10411ER1 8114ER1 4605ER1 1784ER5 1815ER5 10321ER5 8043ER5 4558ER5; 10309ER1 740ER1 10219ER5 732ER5; 1797ER1 3832ER1 8373ER1 3464ER1 5777ER1 4975ER1 9030ER1 8114ER1 4605ER1 9360ER1 1783ER5 3795ER5 9280ER5 3431ER5 5722ER5 4925ER5 8950ER5 8043ER5 4558ER5 8297ER5; 10617ER1 740ER1 10525ER5 732ER5; 3219ER1 1404ER1 3190ER5 1393ER5; 3679ER1 6663ER1 3643ER5 6603ER5; 10337ER1 3676ER1 10247ER5 3640ER5; 2084ER1 2070ER5; 11329ER1 3677ER1 2445ER1 10154ER1 7809ER1 5194ER1 11237ER5 3641ER5 2427ER5 10069ER5 7739ER5 5144ER5; 5954ER1 5899ER5; 4506ER1 4459ER5
DO  - https://doi.org/10.1504/IJLT.2022.123696
ER  - 



TY  - JOUR
T1  - The Effectiveness of Adaptive versus Non-Adaptive Learning with Digital Educational Games
AN  - 2458997097; EJ1259861
AB  - For the training of academic skills, digital educational games with integrated adaptivity are promising. Adaptive games are considered superior to non-adaptive games, because they constantly assess children's performance, and accordingly adapt the difficulty of the tasks corresponding to the children's individual level. However, empirical evidence with regard to the effectivity of adaptive compared to non-adaptive games is limited. A study was conducted with 191 children from the third year of Kindergarten who were enrolled in one of three conditions, that is, playing an adaptive version of the reading game (RG), a non-adaptive version of the RG or training with pen-and-paper exercises. In all three conditions, children trained emergent reading (phonological awareness and letter knowledge) once a week for 30?min over a period of 5?weeks. Children's performance on cognitive (phonological awareness, letter knowledge, reading fluency) and non-cognitive (motivation, self-concept) factors was assessed. Results revealed a significant improvement in phonological awareness and letter knowledge in all conditions. However, no differences between the conditions were observed with respect to children's improvement on phonological awareness and letter knowledge or on their post-test scores for reading fluency. With regard to motivation and self-concept, again, no differences in these non-cognitive factors were observed across conditions.
JF  - Journal of Computer Assisted Learning
AU  - Vanbecelaere, Stefanie
AU  - Van den Berghe, Katrien
AU  - Cornillie, Frederik
AU  - Sasanguie, Delphine
AU  - Reynvoet, Bert
AU  - Depaepe, Fien
Y1  - 2020/08//
PY  - 2020
DA  - Aug 2020
SP  - 502
EP  - 513
PB  - Wiley-Blackwell
VL  - 36
IS  - 4
SN  - 0266-4909, 0266-4909
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Early Childhood Education
KW  - Elementary Education
KW  - Kindergarten
KW  - Primary Education
KW  - Adaptive Testing
KW  - Educational Games
KW  - Computer Games
KW  - Self Concept
KW  - Emergent Literacy
KW  - Reading Instruction
KW  - Reading Motivation
KW  - Cognitive Development
KW  - Preschool Children
UR  - https://www.proquest.com/scholarly-journals/effectiveness-adaptive-versus-non-learning-with/docview/2458997097/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+Effectiveness+of+Adaptive+versus+Non-Adaptive+Learning+with+Digital+Educational+Games&title=Journal+of+Computer+Assisted+Learning&issn=02664909&date=2020-08-01&volume=36&issue=4&spage=502&au=Vanbecelaere%2C+Stefanie%3BVan+den+Berghe%2C+Katrien%3BCornillie%2C+Frederik%3BSasanguie%2C+Delphine%3BReynvoet%2C+Bert%3BDepaepe%2C+Fien&isbn=&jtitle=Journal+of+Computer+Assisted+Learning&btitle=&rft_id=info:eric/EJ1259861&rft_id=info:doi/10.1111%2Fjcal.12416
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-05-24
N1  - SubjectsTermNotLitGenreText - 3249ER1 4328ER1 128ER1 3220ER5 4285ER5 126ER5; 2060ER1 4328ER1 128ER1 2046ER5 4285ER5 126ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 5722ER1 5331ER1 5668ER5 5281ER5; 8229ER1 11798ER1 1491ER1 321ER1 8114ER1 4605ER1 8156ER5 11701ER5 1480ER5 318ER5 8043ER5 4558ER5; 8754ER1 5309ER1 8678ER5 5259ER5; 3425ER1 6179ER1 3394ER5 6120ER5; 1724ER1 5120ER1 2820ER1 1710ER5 5070ER5 2799ER5; 8761ER1 6915ER1 8685ER5 6852ER5; 9566ER1 9485ER5
DO  - https://doi.org/10.1111/jcal.12416
ER  - 



TY  - JOUR
T1  - Classification and Regression Tree and Computer Adaptive Testing in Cardiac Rehabilitation: Instrument Validation Study
AN  - 2737517712
AB  - Background: There is a need for shorter-length assessments that capture patient questionnaire data while attaining high data quality without an undue response burden on patients. Computerized adaptive testing (CAT) and classification and regression tree (CART) methods have the potential to meet these needs and can offer attractive options to shorten questionnaire lengths.
Objective: The objective of this study was to test whether CAT or CART was best suited to reduce the number of questionnaire items in multiple domains (eg, anxiety, depression, quality of life, and social support) used for a needs assessment procedure (NAP) within the field of cardiac rehabilitation (CR) without the loss of data quality.
Methods: NAP data of 2837 CR patients from a multicenter Cardiac Rehabilitation Decision Support System (CARDSS) Web-based program was used. Patients used a Web-based portal, MyCARDSS, to provide their data. CAT and CART were assessed based on their performances in shortening the NAP procedure and in terms of sensitivity and specificity.
Results: With CAT and CART, an overall reduction of 36% and 72% of NAP questionnaire length, respectively, was achieved, with a mean sensitivity and specificity of 0.765 and 0.817 for CAT, 0.777 and 0.877 for classification trees, and 0.743 and 0.40 for regression trees, respectively.
Conclusions: Both CAT and CART can be used to shorten the questionnaires of the NAP used within the field of CR. CART, however, showed the best performance, with a twice as large overall decrease in the number of questionnaire items of the NAP compared to CAT and the highest sensitivity and specificity. To our knowledge, our study is the first to assess the differences in performance between CAT and CART for shortening questionnaire lengths. Future research should consider administering varied assessments of patients over time to monitor their progress in multiple domains. For CR professionals, CART integrated with MyCARDSS would provide a feedback loop that informs the rehabilitation progress of their patients by providing real-time patient measurements.
JF  - Journal of Medical Internet Research
AU  - Peute, Linda
AU  - Scheeve, Thom
AU  - Jaspers, Monique
Y1  - 2020/01//
PY  - 2020
DA  - Jan 2020
CY  - Toronto
PB  - Gunther Eysenbach MD MPH, Associate Professor
PP  - Toronto
VL  - 22
IS  - 1
KW  - Medical Sciences--Computer Applications
KW  - psychometrics
KW  - computing methodologies
KW  - mHealth
KW  - internet
KW  - cardiac rehabilitation
KW  - needs assessment
KW  - Computer adaptive testing
KW  - Anxiety
KW  - Questionnaires
KW  - Rehabilitation
KW  - Likert scale
KW  - Web portals
KW  - Internet
KW  - Social support
KW  - Patients
KW  - Quality of life
KW  - Classification
KW  - Clinics
KW  - Heart attacks
KW  - Validation studies
KW  - Decision making
KW  - Needs assessment
KW  - Trees
KW  - Sensitivity
KW  - Cardiovascular diseases
KW  - Mental depression
KW  - Professionals
KW  - Algorithms
KW  - Computerization
KW  - Computerized decision support systems
UR  - https://www.proquest.com/scholarly-journals/classification-regression-tree-computer-adaptive/docview/2737517712/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aassia&atitle=Classification+and+Regression+Tree+and+Computer+Adaptive+Testing+in+Cardiac+Rehabilitation%3A+Instrument+Validation+Study&title=Journal+of+Medical+Internet+Research&issn=&date=2020-01-01&volume=22&issue=1&spage=e12509&au=Peute%2C+Linda%3BScheeve%2C+Thom%3BJaspers%2C+Monique&isbn=&jtitle=Journal+of+Medical+Internet+Research&btitle=&rft_id=info:eric/&rft_id=info:doi/10.2196%2F12509
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA)
N1  - Copyright - © 2020. This work is licensed under https://creativecommons.org/licenses/by/4.0/  (the “License”).  Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.
N1  - Zuletzt aktualisiert - 2022-11-18
DO  - https://doi.org/10.2196/12509
ER  - 



TY  - RPRT
T1  - A Computer Adaptive Measure of Reading Motivation
AN  - 2488224192; ED607640
AB  - Background: The importance of reading motivation has led to the development of a large number of self-report reading motivation measures; however, there is still a need for a usable measure of adolescent reading motivation that captures a large number of theoretically and empirically distinct constructs. Methods: The current paper details the development and validation of a computer adapted measure of reading motivation, the Adaptive Reading Motivation Measure (ARMM), which assesses constructs of curiosity, involvement, interest, value, challenge, grades, recognition, competition, avoidance, self-efficacy, perceived difficulty, preference for autonomy, social motivation, prosocial goals, and antisocial goals for reading. Results: Model fit indicated that hierarchical multidimensional models fit better than models without a hierarchical structure. The validation results indicate that females scored higher than males and younger students scored higher than older students on most ARMM scores when scores were derived using a higher-order model. In addition, these scores correlated significantly to reading behavior, engagement, and achievement and indicated high reliability. Conclusions: The findings suggest that the ARMM would be a valid measure to assess a large number of reading motivation constructs in a short period of time within a classroom setting. [The paper will be published in "Journal of Research in Reading."]
JF  - Grantee Submission
AU  - Davis, Marcia H.
AU  - Wang, Wenhao
AU  - Kingston, Neal M.
AU  - Hock, Michael
AU  - Tonks, Stephen M.
AU  - Tiemann, Gail
Y1  - 2020
PY  - 2020
DA  - 2020
KW  - ERIC, Resources in Education (RIE)
KW  - Elementary Education
KW  - Secondary Education
KW  - Elementary Secondary Education
KW  - Public Schools
KW  - Test Reliability
KW  - Elementary School Students
KW  - Age Differences
KW  - Achievement Tests
KW  - Test Validity
KW  - Secondary School Students
KW  - Adaptive Testing
KW  - Gender Differences
KW  - Test Construction
KW  - Measures (Individuals)
KW  - Computer Assisted Testing
KW  - Reading Habits
KW  - Reading Motivation
KW  - Adolescents
KW  - Mathematics Achievement
KW  - Reading Achievement
UR  - https://www.proquest.com/reports/computer-adaptive-measure-reading-motivation/docview/2488224192/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=A+Computer+Adaptive+Measure+of+Reading+Motivation&issn=&date=2020-01-01&volume=&issue=&spage=&au=Davis%2C+Marcia+H.%3BWang%2C+Wenhao%3BKingston%2C+Neal+M.%3BHock%2C+Michael%3BTonks%2C+Stephen+M.%3BTiemann%2C+Gail&isbn=&jtitle=&btitle=A+Computer+Adaptive+Measure+of+Reading+Motivation&rft_id=info:eric/ED607640&rft_id=info:doi/10.1111%2F1467-9817.12318
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-05-28
N1  - Vertragsnummer - R305A110148; R305A150193
DO  - https://doi.org/10.1111/1467-9817.12318
ER  - 



TY  - JOUR
T1  - Stopping Rules for Computer Adaptive Testing When Item Banks Have Nonuniform Information
AN  - 2459005490; EJ1254419
AB  - The standard error (SE) stopping rule, which terminates a computer adaptive test (CAT) when the "SE" is less than a threshold, is effective when there are informative questions for all trait levels. However, in domains such as patient-reported outcomes, the items in a bank might all target one end of the trait continuum (e.g., negative symptoms), and the bank may lack depth for many individuals. In such cases, the predicted standard error reduction (PSER) stopping rule will stop the CAT even if the "SE" threshold has not been reached and can avoid administering excessive questions that provide little additional information. By tuning the parameters of the PSER algorithm, a practitioner can specify a desired tradeoff between accuracy and efficiency. Using simulated data for the Patient-Reported Outcomes Measurement Information System Anxiety and Physical Function banks, we demonstrate that these parameters can substantially impact CAT performance. When the parameters were optimally tuned, the PSER stopping rule was found to outperform the "SE" stopping rule overall, particularly for individuals not targeted by the bank, and presented roughly the same number of items across the trait continuum. Therefore, the PSER stopping rule provides an effective method for balancing the precision and efficiency of a CAT.
JF  - International Journal of Testing
AU  - Morris, Scott B.
AU  - Bass, Michael
AU  - Howard, Elizabeth
AU  - Neapolitan, Richard E.
Y1  - 2020
PY  - 2020
DA  - 2020
SP  - 146
EP  - 168
PB  - Routledge
VL  - 20
IS  - 2
SN  - 1530-5058, 1530-5058
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Computer Assisted Testing
KW  - Item Banks
KW  - Psychometrics
KW  - Anxiety
KW  - Evaluation Methods
KW  - Item Response Theory
UR  - https://www.proquest.com/scholarly-journals/stopping-rules-computer-adaptive-testing-when/docview/2459005490/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Stopping+Rules+for+Computer+Adaptive+Testing+When+Item+Banks+Have+Nonuniform+Information&title=International+Journal+of+Testing&issn=15305058&date=2020-01-01&volume=20&issue=2&spage=146&au=Morris%2C+Scott+B.%3BBass%2C+Michael%3BHoward%2C+Elizabeth%3BNeapolitan%2C+Richard+E.&isbn=&jtitle=International+Journal+of+Testing&btitle=&rft_id=info:eric/EJ1254419&rft_id=info:doi/10.1080%2F15305058.2019.1635604
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-05-28
N1  - Vertragsnummer - R01LM011962; R01LM011663
N1  - SubjectsTermNotLitGenreText - 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 5593ER1 5540ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 3679ER1 6663ER1 3643ER5 6603ER5; 8530ER1 8529ER1 938ER1 9466ER1 6042ER1 8454ER5 8453ER5 929ER5 9385ER5 5983ER5; 554ER1 8522ER1 549ER5 8446ER5
DO  - https://doi.org/10.1080/15305058.2019.1635604
ER  - 



TY  - JOUR
T1  - Calibration of an item bank in 474 orthopedic patients using Rasch analysis for computer-adaptive assessment of anxiety
AN  - 2281774362
AB  - Objective:To calibrate an item bank of anxiety-related questions for use in orthopedic patients within a computer-adaptive test.Design:This is a psychometric study.Setting:The sample of orthopedic patients was recruited in two orthopedic rehabilitation clinics in Germany.Subjects:A total of 474 orthopedic rehabilitation patients were recruited for this study.Interventions:Not applicable.Main measures:The main measure is an adapted version of an existing anxiety item pool for cardiovascular rehabilitation patients.Results:The results of the confirmatory factor analysis and Mokken analysis confirmed a one-factor structure and double monotonicity. An anxiety item bank (48 items) could be developed and calibrated using Rasch analysis. It fitted to the Rasch model with a non-significant item–trait interaction (χ2(203) = 172.59; P = .94) and was free of differential item functioning. Unidimensionality could be verified and the person separation reliability was .96. The category threshold parameters varied between 4.72 and 3.16 (7.88 logits).Conclusion:The unidimensional anxiety item bank provides the basis for a computer-adaptive test to assess a wide range of anxiety in rehabilitation patients with orthopedic diseases with very good psychometric characteristics.
JF  - Clinical Rehabilitation
AU  - Kallinger Selina
AU  - Scharm Henry
AU  - Boecker Maren
AU  - Forkmann, Thomas
AU  - Baumeister Harald
AD  - Department of Clinical Psychology and Psychotherapy, Institute of Psychology and Education, University of Ulm, Ulm, Germany ; Institute of Medical Psychology and Medical Sociology, University Hospital of RWTH Aachen, Aachen, Germany ; Department of Clinical Psychology, University of Duisburg-Essen, Essen, Germany ; Department of Clinical Psychology and Psychotherapy, Institute of Psychology and Education, University of Ulm, Ulm, Germany
Y1  - 2019/09//
PY  - 2019
DA  - Sep 2019
SP  - 1468
EP  - 1478
CY  - London
PB  - Sage Publications Ltd.
PP  - London
VL  - 33
IS  - 9
SN  - 02692155
KW  - Medical Sciences--Physical Medicine And Rehabilitation
KW  - Anxiety
KW  - orthopedic disease
KW  - computer-adaptive test
KW  - item bank
KW  - item response theory
KW  - Rasch model
KW  - Confirmatory factor analysis
KW  - Rehabilitation
KW  - Computer adaptive testing
KW  - Parameters
KW  - Reliability
KW  - Quantitative psychology
KW  - Orthopedics
KW  - Questionnaires
KW  - Item response theory
UR  - https://www.proquest.com/scholarly-journals/calibration-item-bank-474-orthopedic-patients/docview/2281774362/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Asociology&atitle=Calibration+of+an+item+bank+in+474+orthopedic+patients+using+Rasch+analysis+for+computer-adaptive+assessment+of+anxiety&title=Clinical+Rehabilitation&issn=02692155&date=2019-09-01&volume=33&issue=9&spage=1468&au=Kallinger+Selina%3BScharm+Henry%3BBoecker+Maren%3BForkmann%2C+Thomas%3BBaumeister+Harald&isbn=&jtitle=Clinical+Rehabilitation&btitle=&rft_id=info:eric/&rft_id=info:doi/10.1177%2F0269215519846225
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA); Sociology Database
N1  - Copyright - © The Author(s) 2019
N1  - Zuletzt aktualisiert - 2022-10-05
DO  - https://doi.org/10.1177/0269215519846225
ER  - 



TY  - JOUR
T1  - Integrating PROMIS® computerized adaptive tests into a web-based intervention for prostate cancer
AN  - 2222645398
AB  - Objective: This study outlined the implementation and feasibility of delivering PROMIS® computer adaptive tests (CATs) using a web-based method to evaluate the impact of a technological adaptation of Cognitive-Behavioral Stress Management (CBSM) on the psychosocial functioning of men with advanced prostate cancer (APC) undergoing hormone therapy. Method: Patients were randomized to a CBSM group intervention (n = 95) or a health promotion (HP) attention-matched control condition (n = 97). Participants attended all sessions via video conference using tablets, and completed PROMIS® computer adaptive tests (CATs) assessing anxiety, depression, fatigue, pain interference, and physical function weekly during the 10-week intervention. Results: Assessment completion rates >50% at week 1 and week 10 demonstrated moderate feasibility of repeatedly administering PROMIS® CATs using a web-based method. Multilevel modeling demonstrated no significant group-by-time interactions from week 1 to week 10 for any of the assessed PROMIS® domains adjusting for sociodemographic and medical covariates. However, simple effects demonstrated decreases in PROMIS® anxiety scores from week 1 to 10 for both groups. Results also demonstrated significant relationships of medical variables to psychosocial functioning across time points. Conclusions: Results highlight the feasibility and benefits of utilizing PROMIS® CATs to repeatedly assess psychosocial functioning using a web-based method and indicate that web-based interventions may be effective for decreasing psychosocial distress and adverse symptoms among men with APC undergoing hormone therapy.
JF  - Health Psychology
AU  - Fox, Rina S
AU  - Moreno, Patricia I
AU  - Yanez, Betina
AU  - Estabrook, Ryne
AU  - Thomas, Jessica
AU  - Bouchard, Laura C
AU  - McGinty, Heather L
AU  - Mohr, David C
AU  - Begale, Mark J
AU  - Flury, Sarah C
AU  - Perry, Kent T
AU  - Kundu, Shilajit D
AU  - Penedo, Frank J
Y1  - 2019/05//
PY  - 2019
DA  - May 2019
SP  - 403
CY  - Washington
PB  - American Psychological Association
PP  - Washington
VL  - 38
IS  - 5
SN  - 0278-6133
KW  - Psychology
KW  - Intervention
KW  - Computer adaptive testing
KW  - Pain
KW  - Hormone replacement therapy
KW  - Health promotion
KW  - Stress management
KW  - Prostate cancer
KW  - Assessment
KW  - Physical ability
KW  - Internet
KW  - Prostate
KW  - Cognitive aspects
KW  - Men
KW  - Fatigue
KW  - Feasibility
KW  - Psychosocial factors
KW  - Computerization
KW  - Psychosocial functioning
KW  - Endocrine therapy
KW  - Psychological distress
KW  - Psychosocial well being
KW  - Cognitive behavioral therapy
KW  - Sociodemographics
KW  - Mental depression
KW  - Anxiety
KW  - Behavior
UR  - https://www.proquest.com/scholarly-journals/integrating-promis®-computerized-adaptive-tests/docview/2222645398/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aassia&atitle=Integrating+PROMIS%26reg%3B+computerized+adaptive+tests+into+a+web-based+intervention+for+prostate+cancer&title=Health+Psychology&issn=02786133&date=2019-05-01&volume=38&issue=5&spage=403&au=Fox%2C+Rina+S%3BMoreno%2C+Patricia+I%3BYanez%2C+Betina%3BEstabrook%2C+Ryne%3BThomas%2C+Jessica%3BBouchard%2C+Laura+C%3BMcGinty%2C+Heather+L%3BMohr%2C+David+C%3BBegale%2C+Mark+J%3BFlury%2C+Sarah+C%3BPerry%2C+Kent+T%3BKundu%2C+Shilajit+D%3BPenedo%2C+Frank+J&isbn=&jtitle=Health+Psychology&btitle=&rft_id=info:eric/&rft_id=info:doi/10.1037%2Fhea0000672
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA)
N1  - Copyright - Copyright American Psychological Association May 2019
N1  - Zuletzt aktualisiert - 2022-08-22
DO  - https://doi.org/10.1037/hea0000672
ER  - 



TY  - JOUR
T1  - Controlling Construct-Irrelevant Factors through Computer-Based Testing: Disengagement, Anxiety, & Cheating
AN  - 2228687459; EJ1208940
AB  - A decision of whether to move from paper-and-pencil to computer-based tests is based largely on a careful weighing of the potential benefits of a change against its costs, disadvantages, and challenges. This paper briefly discusses the trade-offs involved in making such a transition, and then focuses on a relatively unexplored benefit of computer-based tests -- the control of construct-irrelevant factors that can threaten test score validity. Several unique advantages provided by computer-based tests are described, and how these advantages can be used to manage the effects of several common construct-irrelevant factors is discussed. Ultimately, the potential for expanded control may prove to be one of the most important benefits of computer-based tests.
JF  - Education Inquiry
AU  - Wise, Steven L.
Y1  - 2019
PY  - 2019
DA  - 2019
SP  - 21
EP  - 33
PB  - Routledge
VL  - 10
IS  - 1
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Cheating
KW  - Test Wiseness
KW  - Test Format
KW  - Computer Assisted Testing
KW  - Scores
KW  - Test Validity
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/controlling-construct-irrelevant-factors-through/docview/2228687459/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Controlling+Construct-Irrelevant+Factors+through+Computer-Based+Testing%3A+Disengagement%2C+Anxiety%2C+%26amp%3B+Cheating&title=Education+Inquiry&issn=2000-4508&date=2019-01-01&volume=10&issue=1&spage=21&au=Wise%2C+Steven+L.&isbn=&jtitle=Education+Inquiry&btitle=&rft_id=info:eric/EJ1208940&rft_id=info:doi/10.1080%2F20004508.2018.1490127
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - -1
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 1420ER1 552ER1 9858ER1 921ER1 1409ER5 547ER5 9775ER5 912ER5; 10918ER1 10826ER5; 9485ER1 2602ER1 9404ER5 2584ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10917ER1 11346ER1 3677ER1 2445ER1 10154ER1 10825ER5 11254ER5 3641ER5 2427ER5 10069ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 10898ER1 10806ER5
DO  - https://doi.org/10.1080/20004508.2018.1490127
ER  - 



TY  - JOUR
T1  - Exam Anxiety: Using Paired Adaptive Tests to Reduce Stress in Business Classes
AN  - 2228651872; EJ1203830
AB  - To reduce test-taking anxiety among businesses students, a Paired Adaptive Test (PAT) system was developed that allows students two chances to answer exam questions. In the study 46 students from three sections of Survey of International Business at Utah Valley University were given exams using the PAT. At the end of the semester, students were asked to complete a survey on test-taking anxiety for that class and other classes. The results indicated a twelve percent lower test-taking anxiety overall score for the PAT system and as much as 20.85% lower scores for questions key to taking specific exams. The implications of this research are that the PAT method could significantly reduce exam anxiety for students while providing a good assessment of their subject knowledge.
JF  - e-Journal of Business Education and Scholarship of Teaching
AU  - Seeley, Eugene L.
AU  - Andrade, Maureen
AU  - Miller, Ronald Mellado
Y1  - 2018/12//
PY  - 2018
DA  - Dec 2018
SP  - 1
EP  - 13
PB  - Australian Business Education Research Association
VL  - 12
IS  - 3
KW  - Utah
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Higher Education
KW  - Postsecondary Education
KW  - Adaptive Testing
KW  - College Students
KW  - Stress Management
KW  - Scores
KW  - Business Administration Education
KW  - Test Anxiety
KW  - Outcomes of Education
UR  - https://www.proquest.com/scholarly-journals/exam-anxiety-using-paired-adaptive-tests-reduce/docview/2228651872/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Exam+Anxiety%3A+Using+Paired+Adaptive+Tests+to+Reduce+Stress+in+Business+Classes&title=e-Journal+of+Business+Education+and+Scholarship+of+Teaching&issn=1835-9132&date=2018-12-01&volume=12&issue=3&spage=1&au=Seeley%2C+Eugene+L.%3BAndrade%2C+Maureen%3BMiller%2C+Ronald+Mellado&isbn=&jtitle=e-Journal+of+Business+Education+and+Scholarship+of+Teaching&btitle=&rft_id=info:eric/EJ1203830&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 10277ER1 10189ER5; 1829ER1 10411ER1 8114ER1 4605ER1 1815ER5 10321ER5 8043ER5 4558ER5; 1216ER1 8365ER1 3192ER1 1207ER5 8290ER5 3164ER5; 7549ER1 7480ER5; 9485ER1 2602ER1 9404ER5 2584ER5; Utah
ER  - 



TY  - JOUR
T1  - Accuracy of the of the PROMIS-57 questionnaire to identify significant depressive and anxiety symptoms among patients on hemodialysis
AN  - 2088794123
AB  - Aims: To evaluate the accuracy of the depression and anxiety domains of the Patient Reported Outcomes Measurement Information System, 57 item (PROMIS-57) profile questionnaire among hemodialysis patients. Methods: In a cross-sectional, convenience sample of patients undergoing hemodialysis, 113 patients completed the PROMIS-57 (includes PROMIS-29), GAD-7 and PHQ-9 questionnaires. Raw scores of legacy tools were converted to calculated PROMIS T-scores using PROsetta Stone© crosswalk files. A cut off score of 10 on GAD-7 and PHQ-9 identified clinically significant anxiety or depression, respectively. Corresponding PROsetta stone cut ofFs were used to categorize depression and anxiety on the reported PROMIS-57 scales. We computed sensitivity, specificity, positive predictive and negative predictive values. Cohens Kappa was used to assess degree of agreement between legacy and respective PROMIS domains. Results: Of 113 participants, mean (SD) age was 50 (17) years, 57% were male, 42% white. According to legacy instruments, 13% had moderate to severe anxiety, 27% had depression, while reported PROMIS-57 scores yielded 14% with anxiety and 15% with depression. Calculated anxiety scores showed strong correlations with reported PROMIS-57 (r=0.695, p<0.001) and PROMIS-29 (r=0.611, p<0.001) scores. Similarly, calculated depression scores showed strong correlations with reported PROMIS-57 (r=0.627, p<0.001) and PROMIS-29 (r=0.594, p<0.001) scores. Cut off scores generated from legacy instruments for moderate-severe anxiety and depression had high specificity (anxiety=0.93, depression=0.95) and moderate sensitivity (anxiety=0.60, depression=0.43). Kappa values indicated moderate agreement between GAD-7 categorization of anxiety vs PROMIS-57 (K=0.51) and PROMIS-29 (K=0.47); also between PHQ-9 classification of depression versus PROMIS-57 (K=0.45) and PROMIS-29 (K=0.41). Conclusion: The PROMIS-57 depression and anxiety domains are valid self-report tools to assess depressive and anxiety symptoms among hemodialysis patients. Further studies are needed to assess if accuracy can be improved by using the computer adaptive testing PROMIS item banks.
JF  - Journal of Psychosomatic Research
AU  - Bansal, A
AU  - Ekundayo, O
AU  - Xu, A
AU  - Li, S
AU  - Tang, E
AU  - Li, M
AU  - Mucsi, I
AU  - Novak, M
AD  - University Health Network, Toronto, Canada ; University Health Network, Toronto, Canada
Y1  - 2018/06//
PY  - 2018
DA  - Jun 2018
SP  - 89
CY  - London
PB  - Elsevier Science Ltd.
PP  - London
VL  - 109
SN  - 0022-3999
KW  - Medical Sciences--Psychiatry And Neurology
KW  - Accuracy
KW  - Questionnaires
KW  - Mental depression
KW  - Patients
KW  - Hemodialysis
KW  - Measurement
KW  - Computer adaptive testing
KW  - Classification
KW  - Information systems
KW  - Sensitivity
KW  - Glutamate decarboxylase
KW  - Anxiety
KW  - Stone
KW  - Dialysis
KW  - Generalized anxiety disorder
KW  - Self report
UR  - https://www.proquest.com/scholarly-journals/accuracy-promis-57-questionnaire-identify/docview/2088794123/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aassia&atitle=Accuracy+of+the+of+the+PROMIS-57+questionnaire+to+identify+significant+depressive+and+anxiety+symptoms+among+patients+on+hemodialysis&title=Journal+of+Psychosomatic+Research&issn=00223999&date=2018-06-01&volume=109&issue=&spage=89&au=Bansal%2C+A%3BEkundayo%2C+O%3BXu%2C+A%3BLi%2C+S%3BTang%2C+E%3BLi%2C+M%3BMucsi%2C+I%3BNovak%2C+M&isbn=&jtitle=Journal+of+Psychosomatic+Research&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA)
N1  - Copyright - Copyright Elsevier Science Ltd. Jun 2018
N1  - Zuletzt aktualisiert - 2023-01-26
ER  - 



TY  - JOUR
T1  - Correlation of PROMIS CAT instruments with Oswestry Disability Index in chiropractic patients
AN  - 2088124940
AB  - Background The inefficiency associated with collecting standard validated instruments has been a barrier to routine use. We utilized computer adaptive testing (CAT) instruments available through Patient-Reported Outcomes Measurement Information System (PROMIS) and correlated these with the Oswestry Disability Index (ODI). Methods All measurements were collected at a routine chiropractic visit. The ODI assessment was used for comparison as a widely used patient reported outcomes instrument. Results The average time to complete all questions during an office visit was 170 ± 67 s (average ± Stdev) to answer 25 ± 6 questions. Regression analysis revealed a good linear fit between ODI and both PROMIS pain behavior and physical function with R2 values of 0.5219 and 0.6754 respectively, and a good linear fit between anxiety and depression with R2 values of 0.5236. Conclusions PROMIS CAT instruments can be efficiently administered during routine clinical visits and correlations values found validate the utility when compared to ODI.
JF  - Complementary Therapies in Clinical Practice
AU  - Papuga, M Owen
AU  - Barnes, Alicia L
AD  - New York Chiropractic College, 2360 State Route 89, Seneca Falls, NY 13148, United States ; New York Chiropractic College, 2360 State Route 89, Seneca Falls, NY 13148, United States
Y1  - 2018/05//
PY  - 2018
DA  - May 2018
SP  - 85
CY  - Dordrecht
PB  - Elsevier Science Ltd.
PP  - Dordrecht
VL  - 31
SN  - 1744-3881
KW  - Medical Sciences--Nurses And Nursing
KW  - Pain
KW  - Mental depression
KW  - Chiropractic medicine
KW  - Chiropractic
KW  - Measurement
KW  - Computer adaptive testing
KW  - Physical ability
KW  - Values
KW  - Disability
KW  - Anxiety
UR  - https://www.proquest.com/scholarly-journals/correlation-promis-cat-instruments-with-oswestry/docview/2088124940/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aassia&atitle=Correlation+of+PROMIS+CAT+instruments+with+Oswestry+Disability+Index+in+chiropractic+patients&title=Complementary+Therapies+in+Clinical+Practice&issn=17443881&date=2018-05-01&volume=31&issue=&spage=85&au=Papuga%2C+M+Owen%3BBarnes%2C+Alicia+L&isbn=&jtitle=Complementary+Therapies+in+Clinical+Practice&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA)
N1  - Copyright - Copyright Elsevier Science Ltd. May 2018
N1  - Zuletzt aktualisiert - 2022-10-05
ER  - 



TY  - JOUR
T1  - An Adaptive Test Analysis Based on Students' Motivation
AN  - 2461133504; EJ1195643
AB  - Computerized Adaptive Testing (CAT) is now widely used. However, inserting new items into the question bank of a CAT requires a great effort that makes impractical the wide application of CAT in classroom teaching. One solution would be to use the tacit knowledge of the teachers or experts for a pre-classification and calibrate during the execution of tests with these items. Thus, this research consists of a comparative case study between a Stratified Adaptive Test (SAT), based on the tacit knowledge of a teacher, and a CAT based on Item Response Theory (IRT). The tests were applied in seven Computer Networks courses. The results indicate that levels of "anxiety" expressed in the use of the SAT were better than those using the CAT, in addition to being simpler to implement. In this way, it is recommended the implementation of a SAT, where the strata are initially based on the tacit knowledge of the teacher and later, as a result of an IRT calibration.
JF  - Informatics in Education
AU  - Yoshioka, Sérgio R. I.
AU  - Ishitani, Lucila
Y1  - 2018
PY  - 2018
DA  - 2018
SP  - 381
EP  - 404
PB  - Vilnius University Institute of Mathematics and Informatics
VL  - 17
IS  - 2
SN  - 1648-5831, 1648-5831
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Test Theory
KW  - Comparative Analysis
KW  - Test Reliability
KW  - Computer Assisted Testing
KW  - Item Banks
KW  - Test Validity
KW  - Anxiety
KW  - Computer Attitudes
KW  - Item Response Theory
UR  - https://www.proquest.com/scholarly-journals/adaptive-test-analysis-based-on-students/docview/2461133504/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=An+Adaptive+Test+Analysis+Based+on+Students%27+Motivation&title=Informatics+in+Education&issn=16485831&date=2018-01-01&volume=17&issue=2&spage=381&au=Yoshioka%2C+S%C3%A9rgio+R.+I.%3BIshitani%2C+Lucila&isbn=&jtitle=Informatics+in+Education&btitle=&rft_id=info:eric/EJ1195643&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 48
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 10358ER1 6915ER1 10268ER5 6852ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 554ER1 8522ER1 549ER5 8446ER5; 2044ER1 740ER1 2030ER5 732ER5; 10914ER1 10966ER1 10822ER5 10874ER5; 10905ER1 8884ER1 3677ER1 2445ER1 10154ER1 10813ER5 8808ER5 3641ER5 2427ER5 10069ER5; 10917ER1 11346ER1 3677ER1 2445ER1 10154ER1 10825ER5 11254ER5 3641ER5 2427ER5 10069ER5; 1980ER1 3679ER1 6663ER1 1966ER5 3643ER5 6603ER5; 5593ER1 5540ER5
ER  - 



TY  - JOUR
T1  - The Achievement Gap or the Engagement Gap? Investigating the Sensitivity of Gaps Estimates to Test Motivation
AN  - 2155985230; EJ1193522
AB  - This study estimated male-female and Black-White achievement gaps without accounting for low test motivation, then compared those estimates to ones that used several approaches to addressing rapid guessing. Researchers investigated two issues: (1) The differences in rates of rapid guessing across subgroups and (2) How much achievement gap estimates change when rapid guessing is addressed. The study used reading and mathematics scores from the Measures of Academic Progress (MAP), a test administered in nearly all U.S. states. Results suggest that rapid guessing occurs at very different rates across subgroups. However, rapid guessing generally has a mild effect on gaps estimates, although there are cases where failing to account for low test motivation may be impacting fundamental inferences made based on gaps. As part of the second question, differences across approaches to accounting for rapid guessing were examined. Results suggest that rapid guessing occurs at very different rates across subgroups. However, rapid guessing generally has a mild effect on gaps estimates, although there are cases where failing to account for low test motivation may be impacting fundamental inferences made based on gaps.
JF  - Applied Measurement in Education
AU  - Soland, James
Y1  - 2018
PY  - 2018
DA  - 2018
SP  - 312
EP  - 323
PB  - Routledge
VL  - 31
IS  - 4
SN  - 0895-7347, 0895-7347
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Learner Engagement
KW  - White Students
KW  - Achievement Gap
KW  - Reading Tests
KW  - Scores
KW  - Racial Differences
KW  - Inferences
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Gender Differences
KW  - Mathematics Tests
KW  - Computer Assisted Testing
KW  - African American Students
KW  - Guessing (Tests)
UR  - https://www.proquest.com/scholarly-journals/achievement-gap-engagement-investigating/docview/2155985230/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+Achievement+Gap+or+the+Engagement+Gap%3F+Investigating+the+Sensitivity+of+Gaps+Estimates+to+Test+Motivation&title=Applied+Measurement+in+Education&issn=08957347&date=2018-01-01&volume=31&issue=4&spage=312&au=Soland%2C+James&isbn=&jtitle=Applied+Measurement+in+Education&btitle=&rft_id=info:eric/EJ1193522&rft_id=info:doi/10.1080%2F08957347.2018.1495213
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 39
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 4615ER1 9039ER1 921ER1 4568ER5 8959ER5 912ER5; 101ER1 99ER5; 10358ER1 6915ER1 10268ER5 6852ER5; 5954ER1 5899ER5; 4348ER1 4305ER5; 8657ER1 2875ER1 8581ER5 2854ER5; 295ER1 298ER1 7250ER1 8114ER1 4605ER1 10411ER1 292ER5 10321ER5 8043ER5 4558ER5 295ER5 7186ER5; 11624ER1 10411ER1 8114ER1 4605ER1 11626ER1 11528ER5 10321ER5 8043ER5 4558ER5 11529ER5; 8774ER1 11371ER1 10925ER1 6527ER1 8698ER5 11279ER5 10833ER5 6468ER5; 6503ER1 10925ER1 6527ER1 6444ER5 10833ER5 6468ER5; 9485ER1 2602ER1 9404ER5 2584ER5; 5187ER1 5137ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5
DO  - https://doi.org/10.1080/08957347.2018.1495213
ER  - 



TY  - JOUR
T1  - Computer-Adaptive Testing: Implications for Students' Achievement, Motivation, Engagement, and Subjective Test Experience
AN  - 2013521072; EJ1166166
AB  - The present study investigated the implications of computer-adaptive testing (operationalized by way of multistage adaptive testing; MAT) and "conventional" fixed order computer testing for various test-relevant outcomes in numeracy, including achievement, test-relevant motivation and engagement, and subjective test experience. It did so among N = 12,736 Australian elementary (years 3 and 5) and secondary (years 7 and 9) school students. Multilevel modeling assessed the extent to which Level 1 (student) test condition (fixed order vs. adaptive), gender, and year group factors and Level 2 (school) socioeducational advantage, location, structure, and size factors predicted students' test-relevant outcomes. In terms of statistically significant main effects, students in the computer-adaptive testing condition generated lower achievement error rates (i.e., higher measurement precision). Other statistically significant computer-adaptive test effects emerged as a function of year-level and gender, with positive effects of computer-adaptive testing being relatively greater for females and older students: these students achieved more highly (year 9 students), reported higher test-relevant motivation and engagement (year 9 students), and reported more positive subjective test experience (females and year 9 students). These findings (a) confirm that computer-adaptive testing yields greater achievement measurement precision, (b) suggest some positive test-relevant motivation and engagement effects from computer-adaptive testing, (c) counter claims that computer-adaptive testing reduces students' test-relevant motivation, engagement, and subjective experience, and (d) suggest positive computer-adaptive testing effects for older students at a developmental stage when they are typically less motivated and engaged.
JF  - Journal of Educational Psychology
AU  - Martin, Andrew J.
AU  - Lazendic, Goran
Y1  - 2018/01//
PY  - 2018
DA  - Jan 2018
SP  - 27
EP  - 45
PB  - American Psychological Association
VL  - 110
IS  - 1
SN  - 0022-0663, 0022-0663
KW  - Australia
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Elementary Education
KW  - Learner Engagement
KW  - Elementary School Students
KW  - Achievement Tests
KW  - Socioeconomic Status
KW  - School Size
KW  - Foreign Countries
KW  - Statistical Significance
KW  - Secondary School Students
KW  - Student Experience
KW  - Gender Differences
KW  - Geographic Location
KW  - Student Motivation
KW  - Computer Assisted Testing
KW  - Instructional Program Divisions
KW  - Academic Achievement
KW  - Predictor Variables
KW  - Numeracy
KW  - Statistical Analysis
UR  - https://www.proquest.com/scholarly-journals/computer-adaptive-testing-implications-students/docview/2013521072/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Computer-Adaptive+Testing%3A+Implications+for+Students%27+Achievement%2C+Motivation%2C+Engagement%2C+and+Subjective+Test+Experience&title=Journal+of+Educational+Psychology&issn=00220663&date=2018-01-01&volume=110&issue=1&spage=27&au=Martin%2C+Andrew+J.%3BLazendic%2C+Goran&isbn=&jtitle=Journal+of+Educational+Psychology&btitle=&rft_id=info:eric/EJ1166166&rft_id=info:doi/10.1037%2Fedu0000205
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 102
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 3407ER1 10411ER1 8114ER1 4605ER1 3377ER5 10321ER5 8043ER5 4558ER5; 9534ER1 10411ER1 8114ER1 4605ER1 9453ER5 10321ER5 8043ER5 4558ER5; 4348ER1 4305ER5; 5331ER1 5281ER5; 9957ER1 10228ER1 9873ER5 10141ER5; 4392ER1 4348ER5; 8200ER1 8128ER5; 4166ER1 4394ER1 4124ER5 4350ER5; 29ER1 98ER1 28ER5 96ER5; 10358ER1 6915ER1 10268ER5 6852ER5; 5954ER1 5899ER5; 7286ER1 7222ER5; 10340ER1 3736ER1 865ER1 10250ER5 3700ER5 856ER5; 109ER1 10925ER1 6527ER1 107ER5 10833ER5 6468ER5; 9396ER1 5288ER1 9316ER5 5238ER5; 10210ER1 2604ER1 3679ER1 6663ER1 10125ER5 2586ER5 3643ER5 6603ER5; 10222ER1 10210ER1 2604ER1 3679ER1 6663ER1 10136ER5 10125ER5 2586ER5 3643ER5 6603ER5; Australia
DO  - https://doi.org/10.1037/edu0000205
ER  - 



TY  - JOUR
T1  - ATS-PD: An Adaptive Testing System for Psychological Disorders
AN  - 1969007016; EJ1154541
AB  - The clinical assessment of mental disorders can be a time-consuming and error-prone procedure, consisting of a sequence of diagnostic hypothesis formulation and testing aimed at restricting the set of plausible diagnoses for the patient. In this article, we propose a novel computerized system for the adaptive testing of psychological disorders. The proposed system combines a mathematical representation of psychological disorders, known as the "formal psychological assessment," with an algorithm designed for the adaptive assessment of an individual's knowledge. The assessment algorithm is extended and adapted to the new application domain. Testing the system on a real sample of 4,324 healthy individuals, screened for obsessive-compulsive disorder, we demonstrate the system's ability to support clinical testing, both by identifying the correct critical areas for each individual and by reducing the number of posed questions with respect to a standard written questionnaire.
JF  - Educational and Psychological Measurement
AU  - Donadello, Ivan
AU  - Spoto, Andrea
AU  - Sambo, Francesco
AU  - Badaloni, Silvana
AU  - Granziol, Umberto
AU  - Vidotto, Giulio
Y1  - 2017/10//
PY  - 2017
DA  - Oct 2017
SP  - 792
EP  - 815
PB  - SAGE Publications
VL  - 77
IS  - 5
SN  - 0013-1644, 0013-1644
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Accuracy
KW  - Anxiety Disorders
KW  - Mathematical Formulas
KW  - Psychological Evaluation
KW  - Mental Disorders
KW  - Computer Assisted Testing
KW  - Questionnaires
KW  - Markov Processes
KW  - Clinical Diagnosis
UR  - https://www.proquest.com/scholarly-journals/ats-pd-adaptive-testing-system-psychological/docview/1969007016/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=ATS-PD%3A+An+Adaptive+Testing+System+for+Psychological+Disorders&title=Educational+and+Psychological+Measurement&issn=00131644&date=2017-10-01&volume=77&issue=5&spage=792&au=Donadello%2C+Ivan%3BSpoto%2C+Andrea%3BSambo%2C+Francesco%3BBadaloni%2C+Silvana%3BGranziol%2C+Umberto%3BVidotto%2C+Giulio&isbn=&jtitle=Educational+and+Psychological+Measurement&btitle=&rft_id=info:eric/EJ1154541&rft_id=info:doi/10.1177%2F0013164416652188
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 48
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 6611ER1 2911ER1 6552ER5 2890ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 8520ER1 3676ER1 8444ER5 3640ER5; 555ER1 6611ER1 2911ER1 550ER5 6552ER5 2890ER5; 1672ER1 5021ER1 1658ER5 4971ER5; 96ER1 3677ER1 2445ER1 10154ER1 94ER5 3641ER5 2427ER5 10069ER5; 8642ER1 6527ER1 8566ER5 6468ER5; 6480ER1 6474ER1 6483ER1 6421ER5 6424ER5 6415ER5; 6423ER1 9769ER1 6663ER1 6364ER5 9687ER5 6603ER5
DO  - https://doi.org/10.1177/0013164416652188
ER  - 



TY  - JOUR
T1  - Modeling Student Test-Taking Motivation in the Context of an Adaptive Achievement Test
AN  - 1826524730; EJ1092448
AB  - This study examined the utility of response time-based analyses in understanding the behavior of unmotivated test takers. For the data from an adaptive achievement test, patterns of observed rapid-guessing behavior and item response accuracy were compared to the behavior expected under several types of models that have been proposed to represent unmotivated test taking behavior. Test taker behavior was found to be inconsistent with these models, with the exception of the effort-moderated model. Effort-moderated scoring was found to both yield scores that were more accurate than those found under traditional scoring, and exhibit improved person fit statistics. In addition, an effort-guided adaptive test was proposed and shown by a simulation study to alleviate item difficulty mistargeting caused by unmotivated test taking.
JF  - Journal of Educational Measurement
AU  - Wise, Steven L.
AU  - Kingsbury, G. Gage
Y1  - 2016///Apr 2016 - Jun
PY  - 2016
DA  - Apr 2016 - Jun 2016
SP  - 86
EP  - 105
PB  - Wiley-Blackwell
VL  - 53
IS  - 1
SN  - 0022-0655, 0022-0655
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Accuracy
KW  - Test Wiseness
KW  - Achievement Tests
KW  - Scoring Formulas
KW  - Models
KW  - Student Behavior
KW  - Guessing (Tests)
KW  - Item Response Theory
UR  - https://www.proquest.com/scholarly-journals/modeling-student-test-taking-motivation-context/docview/1826524730/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Modeling+Student+Test-Taking+Motivation+in+the+Context+of+an+Adaptive+Achievement+Test&title=Journal+of+Educational+Measurement&issn=00220655&date=2016-04-01&volume=53&issue=1&spage=86&au=Wise%2C+Steven+L.%3BKingsbury%2C+G.+Gage&isbn=&jtitle=Journal+of+Educational+Measurement&btitle=&rft_id=info:eric/EJ1092448&rft_id=info:doi/10.1111%2Fjedm.12102
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 109ER1 10925ER1 6527ER1 107ER5 10833ER5 6468ER5; 10358ER1 6915ER1 10268ER5 6852ER5; 10918ER1 10826ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 4615ER1 9039ER1 921ER1 4568ER5 8959ER5 912ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 6838ER1 9769ER1 6663ER1 6775ER5 9687ER5 6603ER5; 9487ER1 6526ER1 6663ER1 9406ER5 6467ER5 6603ER5; 10311ER1 921ER1 10221ER5 912ER5; 96ER1 3677ER1 2445ER1 10154ER1 94ER5 3641ER5 2427ER5 10069ER5
DO  - https://doi.org/10.1111/jedm.12102
ER  - 



TY  - THES
T1  - Using the Rasch Model in a Computer Adaptive Testing Application to Enhance the Measurement Quality of Emotional Intelligence
AN  - 2566224349
AB  - Background: The use of objective measurement via Rasch models in self-report scales has increased in the recent past, which in turn has enabled the development of computer adaptive tests (CATs). Despite significant advances in both objective measurement and computer adaptive applications few studies have ventured into the personality domain and the emergent field of emotional intelligence. The development of CATs of personality attributes holds advantages such as the reduction in items used for the assessment, reduction of respondent fatigue, and greater cooperation from respondents in the assessment. Research purpose: The aim of this study was to develop a computer adaptive test of the trait Self-control sub-scale of a trait-based emotional intelligence inventory (Trait Emotional Intelligence Questionnaire: TEIQue). Secondary objectives were to examine the functioning of the CAT by (a) comparing the CAT with a static version, and (b) to establish a practical approach to developing a computer adaptive solution to existing static fixed format self-report inventories. Research design: Participants were 681 working South African adults who participated in a local validation research project of the TEIQue. All respondents completed an informed consent form indicating willingness to participate in the research process. The self-control scale consists of 31 items. Each item employs a 7-point Likert-type response format. The data analysis entailed three steps. Step 1 focussed on establishing a benchmark based on the static measurement of trait based self-control. The analysis entailed calibrating and composing a core self-control item bank by means of a Rasch rating scale analysis. The Rasch analysis focussed on how well the observed data fitted the measurement model and identifying items that meet the criteria for inclusion into the item bank. The data were analysed for individual item fit, unidimensionality, local independence, and differential item functioning across gender. Items that did not meet the criteria for good fit were excluded from the item bank. The rating scale analysis yielded 16 items that met the requirements of the Rasch model. These items constituted the static item bank. Step 2 involved obtaining person measures and standard errors for the static item bank. Step 3 involved a post hoc CAT simulation of the responses of the 681 persons to the 16 items, where different item selection criteria and stopping rules were applied to obtain CAT based person measures and standard errors. All simulations were carried out with the Firestar software. The aim of this step was to evaluate the correspondence between static person measures (i.e. measures obtained with the full item bank) and adaptive person measures (i.e. measures obtained with the simulated CAT). Main findings: Overall, high correlations were found between person measures of the static inventory and the CAT version. With a 13 out of 16 item strategy a very high correlation (r = .97) was obtained. The 7 out of 16 item strategy yielded a satisfactory, but somewhat weaker result (r = .91). Results showed that on average about ten items were required to obtain a standard error of person measures < .40. Different initial item starting and subsequent item selection strategies yielded largely similar results with no one single strategy clearly appearing to be the best strategy.
JF  - PQDT - Global
AU  - Hobson, Ernest Guy
A3  - De Bruin, Gideon P.
Y1  - 2015
PY  - 2015
DA  - 2015
SP  - 224
CY  - South Africa
PB  - University of Johannesburg (South Africa)
PP  - South Africa
SN  - 9798744425616
KW  - Information processing
KW  - Principal components analysis
KW  - Self control
KW  - Cognitive ability
KW  - Quantitative psychology
KW  - Personality
KW  - Emotional intelligence
KW  - Psychology
KW  - Cognitive psychology
KW  - Research
KW  - 0633:Cognitive psychology
KW  - 0632:Quantitative psychology
KW  - 0621:Psychology
UR  - https://www.proquest.com/dissertations-theses/using-rasch-model-computer-adaptive-testing/docview/2566224349/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=Using+the+Rasch+Model+in+a+Computer+Adaptive+Testing+Application+to+Enhance+the+Measurement+Quality+of+Emotional+Intelligence&issn=&date=2015-01-01&volume=&issue=&spage=&au=Hobson%2C+Ernest+Guy&isbn=9798744425616&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
L2  - https://ujcontent.uj.ac.za/vital/access/manager/Repository/uj:13971?site_name=GlobalView
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2021-09-26
M3  - Ph.D.
M1  - 28332601
ER  - 



TY  - JOUR
T1  - The EORTC emotional functioning computerized adaptive test: phases I-III of a cross-cultural item bank development
AN  - 1531918641; 201413633
AB  - The European Organisation for Research and Treatment of Cancer (EORTC) Quality of Life Group is currently developing computerized adaptive testing measures for the Quality of Life Questionnaire Core-30 (QLQ-C30) scales. The work presented here describes the development of an EORTC item bank for emotional functioning (EF), which is one of the core domains of the QLQ-C30. According to the EORTC guidelines on module development, the development of the EF item bank comprised four phases, of which the phases I-III are reported in the present paper. Phase I involved defining the theoretical framework for the EF item bank and a literature search. Phase II included pre-defined item selection steps and a multi-stage expert review process. In phase III, feedback from cancer patients from different countries was obtained. On the basis of literature search in phase I, a list of 1750 items was generated. These were reviewed and further developed in phase II with a focus on relevance, redundancy, clarity, and difficulty. The development and selection steps led to a preliminary list of 41 items. In phase III, patient interviews (N = 41; Austria, Denmark, Italy, and the UK) were conducted with the preliminary item list, resulting in some minor changes to item wording. The final list comprised 38 items. The phases I-III of the developmental process have resulted in an EF item list that was well accepted by patients in several countries. The items will be subjected to larger-scale field testing in order to establish their psychometric characteristics and their fit to an item response theory model. [Copyright John Wiley and Sons, Ltd.]
JF  - Psycho-Oncology
AU  - Gamper, Eva-Maria
AU  - Groenvold, Mogens
AU  - Petersen, Morten Aa
AU  - Young, Teresa
AU  - Costantini, Anna
AU  - Aaronson, Neil
AU  - Giesinger, Johannes M
AU  - Meraner, Verena
AU  - Kemmler, Georg
AU  - Holzner, Bernhard
Y1  - 2014/04//
PY  - 2014
DA  - April 2014
SP  - 397
EP  - 403
PB  - Wiley Subscription Services Inc.
VL  - 23
IS  - 4
SN  - 1057-9249, 1057-9249
KW  - Wording
KW  - Emotional wellbeing
KW  - Italy
KW  - Developmental processes
KW  - Quality of life
KW  - Cancer
KW  - article
UR  - https://www.proquest.com/scholarly-journals/eortc-emotional-functioning-computerized-adaptive/docview/1531918641/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aassia&atitle=The+EORTC+emotional+functioning+computerized+adaptive+test%3A+phases+I-III+of+a+cross-cultural+item+bank+development&title=Psycho-Oncology&issn=10579249&date=2014-04-01&volume=23&issue=4&spage=397&au=Gamper%2C+Eva-Maria%3BGroenvold%2C+Mogens%3BPetersen%2C+Morten+Aa%3BYoung%2C+Teresa%3BCostantini%2C+Anna%3BAaronson%2C+Neil%3BGiesinger%2C+Johannes+M%3BMeraner%2C+Verena%3BKemmler%2C+Georg%3BHolzner%2C+Bernhard&isbn=&jtitle=Psycho-Oncology&btitle=&rft_id=info:eric/201413633&rft_id=info:doi/
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA)
N1  - Datum Revision - 2014-06-01
N1  - Zuletzt aktualisiert - 2016-09-27
N1  - CODEN - POJCEE
N1  - SubjectsTermNotLitGenreText - Emotional wellbeing; Quality of life; Cancer; Wording; Developmental processes; Italy
ER  - 



TY  - JOUR
T1  - The EORTC emotional functioning computerized adaptive test: phases I-III of a cross-cultural item bank development
AN  - 1515781565
AB  - The European Organisation for Research and Treatment of Cancer (EORTC) Quality of Life Group is currently developing computerized adaptive testing measures for the Quality of Life Questionnaire Core-30 (QLQ-C30) scales. The work presented here describes the development of an EORTC item bank for emotional functioning (EF), which is one of the core domains of the QLQ-C30. According to the EORTC guidelines on module development, the development of the EF item bank comprised four phases, of which the phases I-III are reported in the present paper. Phase I involved defining the theoretical framework for the EF item bank and a literature search. Phase II included pre-defined item selection steps and a multi-stage expert review process. In phase III, feedback from cancer patients from different countries was obtained. On the basis of literature search in phase I, a list of 1750 items was generated. These were reviewed and further developed in phase II with a focus on relevance, redundancy, clarity, and difficulty. The development and selection steps led to a preliminary list of 41 items. In phase III, patient interviews (N = 41; Austria, Denmark, Italy, and the UK) were conducted with the preliminary item list, resulting in some minor changes to item wording. The final list comprised 38 items. The phases I-III of the developmental process have resulted in an EF item list that was well accepted by patients in several countries. The items will be subjected to larger-scale field testing in order to establish their psychometric characteristics and their fit to an item response theory model.
JF  - Psycho - Oncology
AU  - Gamper, Eva-Maria
AU  - Groenvold, Mogens
AU  - Petersen, Morten Aa
AU  - Young, Teresa
AU  - Costantini, Anna
AU  - Aaronson, Neil
AU  - Giesinger, Johannes M
AU  - Meraner, Verena
AU  - Kemmler, Georg
AU  - Holzner, Bernhard
Y1  - 2014/04//
PY  - 2014
DA  - Apr 2014
SP  - 397
CY  - Chichester
PB  - Wiley Subscription Services, Inc.
PP  - Chichester
VL  - 23
IS  - 4
SN  - 10579249
KW  - Psychology
KW  - Oncology
KW  - Quality of life
KW  - Patients
KW  - Emotions
KW  - Cancer
KW  - Questionnaires
KW  - Health informatics
UR  - https://www.proquest.com/scholarly-journals/eortc-emotional-functioning-computerized-adaptive/docview/1515781565/se-2
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aassia&atitle=The+EORTC+emotional+functioning+computerized+adaptive+test%3A+phases+I-III+of+a+cross-cultural+item+bank+development&title=Psycho+-+Oncology&issn=10579249&date=2014-04-01&volume=23&issue=4&spage=397&au=Gamper%2C+Eva-Maria%3BGroenvold%2C+Mogens%3BPetersen%2C+Morten+Aa%3BYoung%2C+Teresa%3BCostantini%2C+Anna%3BAaronson%2C+Neil%3BGiesinger%2C+Johannes+M%3BMeraner%2C+Verena%3BKemmler%2C+Georg%3BHolzner%2C+Bernhard&isbn=&jtitle=Psycho+-+Oncology&btitle=&rft_id=info:eric/&rft_id=info:doi/10.1002%2Fpon.3427
LA  - English
DB  - Applied Social Sciences Index & Abstracts (ASSIA)
N1  - Copyright - Copyright Wiley Subscription Services, Inc. Apr 2014
N1  - Zuletzt aktualisiert - 2018-09-25
N1  - CODEN - POJCEE
DO  - https://doi.org/10.1002/pon.3427
ER  - 



TY  - JOUR
T1  - New Trends of Measurement and Assessment in Distance Education
AN  - 1651861039; EJ1043023
AB  - Distance education is a discipline that offers solutions to some important education problems. Distance education, contribute to the solution to the problems such as; inequality of opportunities, lifelong education, the implementation of a series of individual and social goals that can contribute to and benefit from educational technology and self-learning. In distance education, methods of measurement and assessment must be consistent with the objectives and contents of teaching. A major interest of formative assessment is determining the students' learning level of each behavior in the interested unit. In summative assessment, performances of students on some units are measured broader than formative assessment. A computerized adaptive testing, CAT, is the test managed by computer in which each item is introduced and the decision to stop are dynamically imposed based on the students answers and his/her estimated knowledge level. In CAT applications, students do not take the same test. Despite item numbers and properties of items are different for the students; the precise of measures improves in positioning students on an ability or success continuum in CAT applications. In CAT applications, questions answered by a student depend on the student's ability or learning level. In item response theory, there are some models to estimate a student's ability level, such as three-parameter logistic model. Cheating in exams or other academic assignments can be defined as use resources not allowed to use or having someone else to take exams or assignments. Some precautions must be taken about cheating such as a live proctoring, using web cams, and using a plagiarism detection program.
JF  - Turkish Online Journal of Distance Education
AU  - Kaya, Zeki
AU  - Tan, Seref
Y1  - 2014/01//
PY  - 2014
DA  - Jan 2014
SP  - 206
EP  - 217
PB  - Anadolu University
VL  - 15
IS  - 1
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Measurement
KW  - Evaluation
KW  - Course Content
KW  - Performance Technology
KW  - Educational Trends
KW  - Affective Behavior
KW  - Adaptive Testing
KW  - Cheating
KW  - Distance Education
KW  - Computer Assisted Testing
KW  - Formative Evaluation
KW  - Summative Evaluation
KW  - Trend Analysis
KW  - Item Response Theory
UR  - https://www.proquest.com/scholarly-journals/new-trends-measurement-assessment-distance/docview/1651861039/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=New+Trends+of+Measurement+and+Assessment+in+Distance+Education&title=Turkish+Online+Journal+of+Distance+Education&issn=1302-6488&date=2014-01-01&volume=15&issue=1&spage=206&au=Kaya%2C+Zeki%3BTan%2C+Seref&isbn=&jtitle=Turkish+Online+Journal+of+Distance+Education&btitle=&rft_id=info:eric/EJ1043023&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 22
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 2981ER1 3192ER1 2959ER5 3164ER5; 3316ER1 3287ER5; 6520ER1 6461ER5; 3676ER1 3640ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 1420ER1 552ER1 9858ER1 921ER1 1409ER5 547ER5 9775ER5 912ER5; 7812ER1 3311ER1 10805ER1 7742ER5 3282ER5 10713ER5; 2367ER1 2374ER1 7498ER1 2350ER5 2357ER5 7430ER5; 4201ER1 3676ER1 4159ER5 3640ER5; 10460ER1 3676ER1 10369ER5 3640ER5; 269ER1 921ER1 266ER5 912ER5; 11139ER1 2604ER1 3679ER1 6663ER1 11047ER5 2586ER5 3643ER5 6603ER5
ER  - 



TY  - JOUR
T1  - Test Anxiety, Computer-Adaptive Testing and the Common Core
AN  - 1697499495; EJ1054865
AB  - This paper highlights the current findings and issues regarding the role of computer-adaptive testing in test anxiety. The computer-adaptive test (CAT) proposed by one of the Common Core consortia brings these issues to the forefront. Research has long indicated that test anxiety impairs student performance. More recent research indicates that taking a test in a CAT format can affect the ability estimates of students with test anxiety. Inaccurate measures of ability are disconcerting because of the threat they pose to the validity of test score interpretation. This paper raises concerns regarding how the implementation of a computer-adaptive test for a large-scale common core assessment system could differentially affect students with test anxiety. Issues of fairness and score comparability are raised, and the implications of these issues are discussed.
JF  - Journal of Education and Training Studies
AU  - Colwell, Nicole Makas
Y1  - 2013/10//
PY  - 2013
DA  - Oct 2013
SP  - 50
EP  - 60
PB  - Redfame Publishing Inc
VL  - 1
IS  - 2
SN  - 2324-805X, 2324-805X
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Elementary Secondary Education
KW  - Student Evaluation
KW  - Scores
KW  - Socioeconomic Status
KW  - High Stakes Tests
KW  - Test Bias
KW  - Ability Identification
KW  - Computer Assisted Testing
KW  - Educational Technology
KW  - Effect Size
KW  - Standardized Tests
KW  - Summative Evaluation
KW  - Test Items
KW  - Evaluation Methods
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/test-anxiety-computer-adaptive-testing-common/docview/1697499495/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Test+Anxiety%2C+Computer-Adaptive+Testing+and+the+Common+Core&title=Journal+of+Education+and+Training+Studies&issn=2324805X&date=2013-10-01&volume=1&issue=2&spage=50&au=Colwell%2C+Nicole+Makas&isbn=&jtitle=Journal+of+Education+and+Training+Studies&btitle=&rft_id=info:eric/EJ1054865&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 41
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 3679ER1 6663ER1 3643ER5 6603ER5; 10153ER1 10925ER1 6527ER1 10068ER5 10833ER5 6468ER5; 10891ER1 955ER1 10799ER5 946ER5; 3311ER1 10805ER1 3282ER5 10713ER5; 10900ER1 10808ER5; 2883ER1 2862ER5; 10337ER1 3676ER1 10247ER5 3640ER5; 4ER1 5021ER1 3ER5 4971ER5; 3412ER1 3192ER1 3382ER5 3164ER5; 3324ER1 10210ER1 2604ER1 3679ER1 6663ER1 3295ER5 10125ER5 2586ER5 3643ER5 6603ER5; 9485ER1 2602ER1 9404ER5 2584ER5; 9957ER1 10228ER1 9873ER5 10141ER5; 4807ER1 10925ER1 6527ER1 4759ER5 10833ER5 6468ER5; 10460ER1 3676ER1 10369ER5 3640ER5
ER  - 



TY  - JOUR
T1  - The MMPI-2 Computerized Adaptive Version (MMPI-2-CA) in a Veterans Administration Medical Outpatient Facility
AN  - 1314328688; EJ991778
AB  - The ability to screen quickly and thoroughly for psychological difficulties in existing and returning combat veterans who are seeking treatment for physical ailments would be of significant benefit. In the current study, item and time savings, as well as extratest correlations, associated with an audio-augmented version of the computerized adaptive Minnesota Multiphasic Personality Inventory-2 (MMPI-2-CA) are examined in a group of 273 male veterans, ages 26-87 years. Results indicated an average item savings of approximately 103 items (18.6%), with a corresponding time savings of approximately 12 min (24.3%), for the MMPI-2-CA compared with conventional computerized administration of the test, as well as comparability in terms of test-retest coefficients and correlations with external measures. Future directions of adaptive personality testing are discussed. (Contains 4 tables and 1 footnote.)
JF  - Psychological Assessment
AU  - Forbey, Johnathan D.
AU  - Ben-Porath, Yossef S.
AU  - Arbisi, Paul A.
Y1  - 2012/09//
PY  - 2012
DA  - Sep 2012
SP  - 628
EP  - 639
PB  - American Psychological Association
VL  - 24
IS  - 3
SN  - 1040-3590, 1040-3590
KW  - Minnesota Multiphasic Personality Inventory
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Emotional Disturbances
KW  - Correlation
KW  - Comparative Analysis
KW  - Veterans
KW  - Measures (Individuals)
KW  - Screening Tests
KW  - Personality
KW  - Personality Measures
KW  - Males
KW  - Patients
UR  - https://www.proquest.com/scholarly-journals/mmpi-2-computerized-adaptive-version-ca-veterans/docview/1314328688/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+MMPI-2+Computerized+Adaptive+Version+%28MMPI-2-CA%29+in+a+Veterans+Administration+Medical+Outpatient+Facility&title=Psychological+Assessment&issn=10403590&date=2012-09-01&volume=24&issue=3&spage=628&au=Forbey%2C+Johnathan+D.%3BBen-Porath%2C+Yossef+S.%3BArbisi%2C+Paul+A.&isbn=&jtitle=Psychological+Assessment&btitle=&rft_id=info:eric/EJ991778&rft_id=info:doi/10.1037%2Fa0026509
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 67
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 7854ER1 6527ER1 7784ER5 6468ER5; 7850ER1 7780ER5; 11378ER1 8114ER1 4605ER1 11286ER5 8043ER5 4558ER5; 7738ER1 8114ER1 4605ER1 7668ER5 8043ER5 4558ER5; 6527ER1 6468ER5; 2295ER1 10210ER1 2604ER1 3679ER1 6663ER1 2278ER5 10125ER5 2586ER5 3643ER5 6603ER5; 6344ER1 8114ER1 4605ER1 6285ER5 8043ER5 4558ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1980ER1 3679ER1 6663ER1 1966ER5 3643ER5 6603ER5; 3433ER1 6611ER1 2911ER1 3401ER5 6552ER5 2890ER5; 9494ER1 10925ER1 6527ER1 9413ER5 10833ER5 6468ER5
DO  - https://doi.org/10.1037/a0026509
ER  - 



TY  - JOUR
T1  - Computerized Adaptive Testing, Anxiety Levels, and Gender Differences
AN  - 757171388; EJ896744
AB  - This study compares the amount of test anxiety experienced on a computerized adaptive test (CAT) to a paper-and-pencil test (P&P), as well as the state test anxiety experienced between males and females. Ninety-four middle school CAT examinees were compared to 65 middle school P&P examinees on their responses to the State-Trait Anxiety Inventory for Children (STAIC) after taking a standardized achievement test. Results of a multiple regression showed that P&P examinees had a higher mean STAIC score than CAT examinees after controlling for trait test anxiety and computer anxiety. Evidence of neither a main nor a moderator effect of gender was found. However, a subsequent path analysis gave evidence of an indirect effect of gender on STAIC score mediated by trait test anxiety. Results are discussed in the context of stereotype threat and the implications for the use of CAT in schools, given the digital divide between race and socioeconomic status. Recommendations for future research and practice are offered.
JF  - Social Psychology of Education: An International Journal
AU  - Fritts, Barbara E.
AU  - Marszalek, Jacob M.
Y1  - 2010/09//
PY  - 2010
DA  - Sep 2010
SP  - 441
EP  - 458
PB  - Springer
VL  - 13
IS  - 3
SN  - 1381-2890, 1381-2890
KW  - State Trait Anxiety Inventory for Children
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Middle Schools
KW  - Achievement Tests
KW  - Path Analysis
KW  - Scores
KW  - Socioeconomic Status
KW  - Middle School Students
KW  - Racial Differences
KW  - Stereotypes
KW  - Computer Attitudes
KW  - Adaptive Testing
KW  - Gender Differences
KW  - Comparative Analysis
KW  - Test Format
KW  - Measures (Individuals)
KW  - Computer Assisted Testing
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/computerized-adaptive-testing-anxiety-levels/docview/757171388/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Computerized+Adaptive+Testing%2C+Anxiety+Levels%2C+and+Gender+Differences&title=Social+Psychology+of+Education%3A+An+International+Journal&issn=13812890&date=2010-09-01&volume=13&issue=3&spage=441&au=Fritts%2C+Barbara+E.%3BMarszalek%2C+Jacob+M.&isbn=&jtitle=Social+Psychology+of+Education%3A+An+International+Journal&btitle=&rft_id=info:eric/EJ896744&rft_id=info:doi/10.1007%2Fs11218-010-9113-3
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 41
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 2044ER1 740ER1 2030ER5 732ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 109ER1 10925ER1 6527ER1 107ER5 10833ER5 6468ER5; 7731ER1 6974ER1 10210ER1 2604ER1 3679ER1 6663ER1 7661ER5 6911ER5 10125ER5 2586ER5 3643ER5 6603ER5; 4348ER1 4305ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 1980ER1 3679ER1 6663ER1 1966ER5 3643ER5 6603ER5; 6726ER1 10411ER1 8114ER1 4605ER1 6665ER5 10321ER5 8043ER5 4558ER5; 10898ER1 10806ER5; 6527ER1 6468ER5; 9485ER1 2602ER1 9404ER5 2584ER5; 10243ER1 740ER1 10155ER5 732ER5; 8657ER1 2875ER1 8581ER5 2854ER5; 9957ER1 10228ER1 9873ER5 10141ER5
DO  - https://doi.org/10.1007/s11218-010-9113-3
ER  - 



TY  - JOUR
T1  - Effects of Online Testing on Student Exam Performance and Test Anxiety
AN  - 61797812; EJ873597
AB  - Increased use of course management software to administer course exams online for face-to-face classes raises the question of how well test anxiety and other emotions generalize from the classroom to an online setting. We hypothesized that administering regular course exams in an online format would reduce test anxiety experienced at the time of the exam and improve exam scores. We recruited 69 participants from a psychology course to take classroom- and online-delivered exams, using a counterbalanced crossover design. We found that students who normally experience high levels of test anxiety in the classroom had reduced test anxiety when taking online exams, while the reverse was true for those low in classroom anxiety. Furthermore, the relationship between test anxiety and exam performance was weaker in an online setting than in the classroom. We recommend that instructors evaluate the potential impact of these findings when considering offering examinations online. (Contains 2 tables and 1 figure.)
JF  - Journal of Educational Computing Research
AU  - Stowell, Jeffrey R.
AU  - Bennett, Dan
Y1  - 2010
PY  - 2010
DA  - 2010
SP  - 161
EP  - 171
PB  - Baywood Publishing Company
VL  - 42
IS  - 2
SN  - 0735-6331, 0735-6331
KW  - Self Adapted Testing
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Higher Education
KW  - Adaptive Testing
KW  - Cheating
KW  - Computer Uses in Education
KW  - Test Wiseness
KW  - Educational Psychology
KW  - Computer Assisted Testing
KW  - Educational Technology
KW  - Online Courses
KW  - Test Anxiety
KW  - Tests
UR  - https://www.proquest.com/scholarly-journals/effects-online-testing-on-student-exam/docview/61797812/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Effects+of+Online+Testing+on+Student+Exam+Performance+and+Test+Anxiety&title=Journal+of+Educational+Computing+Research&issn=07356331&date=2010-01-01&volume=42&issue=2&spage=161&au=Stowell%2C+Jeffrey+R.%3BBennett%2C+Dan&isbn=&jtitle=Journal+of+Educational+Computing+Research&btitle=&rft_id=info:eric/EJ873597&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 20
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2099ER1 2098ER1 10811ER1 2085ER5 2084ER5 10719ER5; 3311ER1 10805ER1 3282ER5 10713ER5; 10925ER1 6527ER1 10833ER5 6468ER5; 10918ER1 10826ER5; 3291ER1 4221ER1 8529ER1 938ER1 9466ER1 6042ER1 3262ER5 4179ER5 8453ER5 929ER5 9385ER5 5983ER5; 7420ER1 2099ER1 2098ER1 10811ER1 2379ER1 2544ER1 7356ER5 2085ER5 2084ER5 10719ER5 2362ER5 2526ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1420ER1 552ER1 9858ER1 921ER1 1409ER5 547ER5 9775ER5 912ER5; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5
ER  - 



TY  - JOUR
T1  - Conative Feedback in Computer-Based Assessment
AN  - 61850093; EJ855572
AB  - Feedback is an important educational tool that can support learning and assessment. This article describes types of conative feedback that can support the student's conation, will, volition, or motivation. Any of these types of feedback can be presented to the student before, during, or after an educational activity or a test question. Experimental results found higher student scores using conative feedback during computer-based assessment than without feedback. (Contains 1 table and 3 figures.)
JF  - Computers in the Schools
AU  - Economides, Anastasios A.
Y1  - 2009
PY  - 2009
DA  - 2009
SP  - 207
EP  - 223
PB  - Routledge
VL  - 26
IS  - 3
SN  - 0738-0569, 0738-0569
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Computer Assisted Testing
KW  - Scores
KW  - Feedback (Response)
UR  - https://www.proquest.com/scholarly-journals/conative-feedback-computer-based-assessment/docview/61850093/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Conative+Feedback+in+Computer-Based+Assessment&title=Computers+in+the+Schools&issn=07380569&date=2009-01-01&volume=26&issue=3&spage=207&au=Economides%2C+Anastasios+A.&isbn=&jtitle=Computers+in+the+Schools&btitle=&rft_id=info:eric/EJ855572&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 38
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 3979ER1 5416ER1 8876ER1 3939ER5 5365ER5 8800ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 10358ER1 6915ER1 10268ER5 6852ER5; 9485ER1 2602ER1 9404ER5 2584ER5
ER  - 



TY  - JOUR
T1  - Adjusting to Test Takers
AN  - 61989401; EJ819164
AB  - This article discusses the growing interest in computer-adaptive testing, which supporters say can help guide instruction, increase student motivation, and determine the best use of resources for districts. This method of testing shortens the test by not asking high-achieving students questions that are too easy for them, and likewise not giving struggling students questions that are too hard. However, computer-adaptive assessments are not the best way to evaluate students in every situation, experts point out. Though, they recognize the potential of computer-adaptive testing, experts also voice caution in using this kind of method.
JF  - Education Week
AU  - Ash, Katie
Y1  - 2008/11//
PY  - 2008
DA  - Nov 2008
SP  - 19
EP  - 21
PB  - Editorial Projects in Education
VL  - 28
IS  - 13
SN  - 0277-4232, 0277-4232
KW  - California
KW  - Oregon
KW  - Utah
KW  - No Child Left Behind Act 2001
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Elementary Secondary Education
KW  - Adaptive Testing
KW  - Federal Legislation
KW  - Student Motivation
KW  - Student Evaluation
KW  - Testing Problems
KW  - Computer Assisted Testing
KW  - Educational Legislation
UR  - https://www.proquest.com/scholarly-journals/adjusting-test-takers/docview/61989401/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Adjusting+to+Test+Takers&title=Education+Week&issn=02774232&date=2008-11-01&volume=28&issue=13&spage=19&au=Ash%2C+Katie&isbn=&jtitle=Education+Week&btitle=&rft_id=info:eric/EJ819164&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 10337ER1 3676ER1 10247ER5 3640ER5; 10358ER1 6915ER1 10268ER5 6852ER5; 3967ER1 6016ER1 3927ER5 5958ER5; 3261ER1 6016ER1 3232ER5 5958ER5; 10922ER1 8339ER1 10830ER5 8264ER5; California; Oregon; Utah
ER  - 



TY  - JOUR
T1  - Computerized Adaptive Testing for Polytomous Motivation Items: Administration Mode Effects and a Comparison with Short Forms
AN  - 62043948; EJ773650
AB  - In a randomized experiment (n = 515), a computerized and a computerized adaptive test (CAT) are compared. The item pool consists of 24 polytomous motivation items. Although items are carefully selected, calibration data show that Samejima's graded response model did not fit the data optimally. A simulation study is done to assess possible consequences of model misfit. CAT efficiency was studied by a systematic comparison of the CAT with two types of conventional fixed length short forms, which are created to be good CAT competitors. Results showed no essential administration mode effects. Efficiency analyses show that CAT outperformed the short forms in almost all aspects when results are aggregated along the latent trait scale. The real and the simulated data results are very similar, which indicate that the real data results are not affected by model misfit. (Contains 2 tables, 6 figures and 5 notes.)
JF  - Applied Psychological Measurement
AU  - Hol, A. Michiel
AU  - Vorst, Harrie C. M.
AU  - Mellenbergh, Gideon J.
Y1  - 2007
PY  - 2007
DA  - 2007
SP  - 412
EP  - 429
PB  - SAGE Publications
VL  - 31
IS  - 5
SN  - 0146-6216, 0146-6216
KW  - Netherlands
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Higher Education
KW  - Foreign Countries
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Comparative Analysis
KW  - Test Format
KW  - Simulation
KW  - College Students
KW  - Computer Assisted Testing
KW  - Questionnaires
KW  - Test Items
KW  - Models
KW  - Item Response Theory
UR  - https://www.proquest.com/scholarly-journals/computerized-adaptive-testing-polytomous/docview/62043948/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Computerized+Adaptive+Testing+for+Polytomous+Motivation+Items%3A+Administration+Mode+Effects+and+a+Comparison+with+Short+Forms&title=Applied+Psychological+Measurement&issn=01466216&date=2007-01-01&volume=31&issue=5&spage=412&au=Hol%2C+A.+Michiel%3BVorst%2C+Harrie+C.+M.%3BMellenbergh%2C+Gideon+J.&isbn=&jtitle=Applied+Psychological+Measurement&btitle=&rft_id=info:eric/EJ773650&rft_id=info:doi/10.1177%2F0146621606297314
LA  - English
DB  - ERIC
N1  - Anzahl der Quellenangaben - 39
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 10358ER1 6915ER1 10268ER5 6852ER5; 9769ER1 6663ER1 9687ER5 6603ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 1980ER1 3679ER1 6663ER1 1966ER5 3643ER5 6603ER5; 10900ER1 10808ER5; 6838ER1 9769ER1 6663ER1 6775ER5 9687ER5 6603ER5; 10898ER1 10806ER5; 1829ER1 10411ER1 8114ER1 4605ER1 1815ER5 10321ER5 8043ER5 4558ER5; 4166ER1 4394ER1 4124ER5 4350ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 8642ER1 6527ER1 8566ER5 6468ER5; Netherlands
DO  - https://doi.org/10.1177/0146621606297314
ER  - 



TY  - THES
T1  - Measurement of Korean EFL college students' foreign language classroom speaking anxiety: Evidence of psychometric properties and accuracy of a computerized adaptive test (CAT) with dichotomously scored items using a CAT simulation
AN  - 85626294; 200614254
AB  - Assessment of foreign language speaking anxiety is considered pertinent to assisting practitioners to reduce learners' speaking anxiety. Computerized adaptive testing (CAT) of severity of speaking anxiety has potential advantages over conventional paper-and-pencil (P&P) tests in terms of efficiency, precision, adaptiveness and real-time severity monitoring. Item response theory (IRT) was applied to obtain item characteristics (i.e. anxiety severity and discrimination parameter) and develop an item pool that can be used for a computerized adaptive test to measure severity of speaking anxiety. Based on two-parameter logistic IRT model, the study analyzed responses to a newly constructed English speaking anxiety inventory from a sample of 949 Korean EFL undergraduate students. The study used Principal Component Analysis and DIMTEST in a confirmatory mode to account for construct validity and conducted a computer simulation of CAT to investigate whether a CAT or a P&P test can more accurately estimate test-takers' severity levels of English speaking anxiety, conditional on their true severity of speaking anxiety. Examining construct validity, the results indicated that a principal component analysis (PCA) of the data revealed that 23 percent of the total variation in the data was accounted for by the first component, which exceeds the 20 percent criterion established by Reckase (1979) for assuming unidimensionality and that Cognitive Speaking Anxiety (CSA) items were not dimensionally separable from the Psychosomatic Speaking Anxiety (PSA) items. The study established a pool of 142 items that can be used for a computerized adaptive speaking anxiety severity test. Results of a CAT simulation indicate that a 20-item simulated fixed-length CAT provides better accuracy than that of a P&P test.
JF  - Dissertation Abstracts International, A: The Humanities and Social Sciences
AU  - Yang, Tae-Kyoung
Y1  - 2006
PY  - 2006
DA  - 2006
SP  - 4365
KW  - Anxiety (03350)
KW  - Measures (Instruments) (52300)
KW  - Foreigners (25120)
KW  - Test Validity and Reliability (88800)
KW  - College Students (13250)
KW  - Asian Cultural Groups (04950)
KW  - Computer Modeling and Simulation (14355)
KW  - English as a Second Language Learning (22130)
KW  - Psychometric Analysis (69210)
KW  - dissertation
KW  - 4132: applied linguistics; English as a second/foreign language learning
UR  - https://www.proquest.com/dissertations-theses/measurement-korean-efl-college-students-foreign/docview/85626294/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:Linguistics+and+Language+Behavior+Abstracts+%28LLBA%29&atitle=&title=Measurement+of+Korean+EFL+college+students%27+foreign+language+classroom+speaking+anxiety%3A+Evidence+of+psychometric+properties+and+accuracy+of+a+computerized+adaptive+test+%28CAT%29+with+dichotomously+scored+items+using+a+CAT+simulation&issn=&date=2006-06-01&volume=&issue=&spage=&au=Yang%2C+Tae-Kyoung&isbn=&jtitle=&btitle=&rft_id=info:eric/200614254&rft_id=info:doi/
LA  - English
DB  - Linguistics and Language Behavior Abstracts (LLBA)
N1  - Datum Revision - 2006-12-01
N1  - SuppNotes - AAT 3204228 ; Degree: PhD Thesis publ. date: 2005; Pages: 245; Advisor(s): Chang, Hua-Hua
N1  - Zuletzt aktualisiert - 2016-09-27
N1  - CODEN - DABAA6
N1  - Erste Seite - 4365
N1  - SubjectsTermNotLitGenreText - Anxiety (03350); English as a Second Language Learning (22130); Psychometric Analysis (69210); Computer Modeling and Simulation (14355); Test Validity and Reliability (88800); Measures (Instruments) (52300); College Students (13250); Foreigners (25120); Asian Cultural Groups (04950)
ER  - 



TY  - THES
T1  - Measurement of Korean EFL college students' foreign language classroom speaking anxiety: Evidence of psychometric properties and accuracy of a computerized adaptive test (CAT) with dichotomously scored items using a CAT simulation
AN  - 305382849
AB  - Assessment of foreign language speaking anxiety is considered pertinent to assisting practitioners to reduce learners' speaking anxiety. Computerized adaptive testing (CAT) of severity of speaking anxiety has potential advantages over conventional paper-and-pencil (P&P) tests in terms of efficiency, precision, adaptiveness and real-time severity monitoring.    Item response theory (IRT) was applied to obtain item characteristics (i.e. anxiety severity and discrimination parameter) and develop an item pool that can be used for a computerized adaptive test to measure severity of speaking anxiety.    Based on two-parameter logistic IRT model, the study analyzed responses to a newly constructed English speaking anxiety inventory from a sample of 949 Korean EFL undergraduate students. The study used Principal Component Analysis and DIMTEST in a confirmatory mode to account for construct validity and conducted a computer simulation of CAT to investigate whether a CAT or a P&P test can more accurately estimate test-takers' severity levels of English speaking anxiety, conditional on their true severity of speaking anxiety.    Examining construct validity, the results indicated that a principal component analysis (PCA) of the data revealed that 23 percent of the total variation in the data was accounted for by the first component, which exceeds the 20 percent criterion established by Reckase (1979) for assuming unidimensionality and that Cognitive Speaking Anxiety (CSA) items were not dimensionally separable from the Psychosomatic Speaking Anxiety (PSA) items. The study established a pool of 142 items that can be used for a computerized adaptive speaking anxiety severity test. Results of a CAT simulation indicate that a 20-item simulated fixed-length CAT provides better accuracy than that of a P&P test.
JF  - ProQuest Dissertations and Theses
AU  - Yang, Tae-Kyoung
A3  - Chang, Hua-Hua
Y1  - 2005
PY  - 2005
DA  - 2005
SP  - 245
CY  - United States -- Texas
PB  - The University of Texas at Austin
PP  - United States -- Texas
SN  - 978-0-542-50049-7
KW  - Education
KW  - Accuracy
KW  - College students
KW  - Computerized adaptive test
KW  - EFL
KW  - Foreign language
KW  - Korean
KW  - Psychometric
KW  - Speaking anxiety
KW  - Educational evaluation
KW  - Educational psychology
KW  - Multicultural education
KW  - Higher education
KW  - Educational tests & measurements
KW  - 0455:Multicultural Education
KW  - 0443:Educational evaluation
KW  - 0525:Educational psychology
KW  - 0745:Higher education
KW  - 0288:Educational tests & measurements
UR  - https://www.proquest.com/dissertations-theses/measurement-korean-efl-college-students-foreign/docview/305382849/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=Measurement+of+Korean+EFL+college+students%27+foreign+language+classroom+speaking+anxiety%3A+Evidence+of+psychometric+properties+and+accuracy+of+a+computerized+adaptive+test+%28CAT%29+with+dichotomously+scored+items+using+a+CAT+simulation&issn=&date=2005-01-01&volume=&issue=&spage=&au=Yang%2C+Tae-Kyoung&isbn=978-0-542-50049-7&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2022-10-31
M3  - Ph.D.
M1  - 3204228
ER  - 



TY  - THES
T1  - Factors that affect student performance on the Computer Adaptive Testing National Certification Examination for nurse anesthetists
AN  - 305363312
AB  - The ability to predict the performance of student nurse anesthetists on the Computer Adaptive Testing National Certification Examination (CAT NCE) is an area of concern and interest to nurse anesthesia educators, students, nurse anesthesia administrators, clinicians, and employers. Upon completion of an accredited nurse anesthesia education program, students must successfully pass the CAT NCE in order to practice as a nurse anesthetist. One of the major outcomes of the education of student nurse anesthetists is to provide the community of interest with safe, competent anesthesia practitioners who can pass the CAT NCE.    This study examined 13 academic, demographic, and pre-admission factors, which predict performance on the CAT NCE. This retrospective study reviewed the academic records of 128 student nurse anesthetists who took the CAT NCE between 1996 and 2003. The independent variables included the following: Baccalaureate of Science Degree in Nursing (BSN), nurse anesthesia program grade point average (GPA), age, gender, type of nursing background, number of years of nursing, type of BSN program (traditional, completion), and number of clinical cases and case hours in the nurse anesthesia program. The dependent variable was overall CAT NCE score.    Results of the multiple regression analysis determined that 2 of the 13 independents variables were predictive of student performance on the CAT NCE. These variables included BSN GPA and type of BSN program, which accounted for 15.5% of the variance in overall CAT NCE scores. In addition, a strong positive correlation existed between BSN GPA and CAT NCE scores. All of the other remaining variables showed no significance in the multiple regression or correlation analyses.    The results of this study will be used to examine and further define the admission criteria and curriculum requirements for nurse anesthesia education programs. In the computerized version of the NCE, each candidate's examination is individualized, allowing the results of the examination to be based on the student's individual knowledge, skills, and abilities to determine individual competence. The computer adaptive version of the NCE more precisely determines competence by testing each individual according to his or her abilities.
JF  - ProQuest Dissertations and Theses
AU  - Boytim, Michael
A3  - Madjidi, Farzin
Y1  - 2005
PY  - 2005
DA  - 2005
SP  - 116
CY  - United States -- California
PB  - Pepperdine University
PP  - United States -- California
SN  - 978-0-542-09532-0
KW  - Health and environmental sciences
KW  - Education
KW  - Certification
KW  - Computer Adaptive Testing National Certification Examination
KW  - Nurse anesthetists
KW  - Higher education
KW  - Educational evaluation
KW  - Health education
KW  - 0680:Health education
KW  - 0745:Higher education
KW  - 0288:Educational tests & measurements
UR  - https://www.proquest.com/dissertations-theses/factors-that-affect-student-performance-on/docview/305363312/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=Factors+that+affect+student+performance+on+the+Computer+Adaptive+Testing+National+Certification+Examination+for+nurse+anesthetists&issn=&date=2005-01-01&volume=&issue=&spage=&au=Boytim%2C+Michael&isbn=978-0-542-09532-0&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2021-05-26
M3  - Ed.D.
M1  - 3171834
ER  - 



TY  - JOUR
T1  - Applicable Adaptive Testing Models for School Teachers
AN  - 62208269; EJ654148
AB  - Describes a study conducted in Taipei (Taiwan) that investigated the attitudinal effects of SPRT (Sequential Probability Ratio Test) adaptive testing environment on junior high school students. Discusses test anxiety; student preferences; test adaptability; acceptance of test results; number of items answered; and computer experience. (Author/LRW)
JF  - Educational Media International
AU  - Wang, Albert Chang-hwa
AU  - Chuang, Chi-lin
Y1  - 2002/03//
PY  - 2002
DA  - Mar 2002
SP  - 55
EP  - 59
VL  - 39
IS  - 1
SN  - 0952-3987, 0952-3987
KW  - Taiwan (Taipei)
KW  - Sequential Probability Ratio Test (Wald)
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Junior High Schools
KW  - Student Attitudes
KW  - Foreign Countries
KW  - Junior High School Students
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/applicable-adaptive-testing-models-school/docview/62208269/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Applicable+Adaptive+Testing+Models+for+School+Teachers&title=Educational+Media+International&issn=09523987&date=2002-03-01&volume=39&issue=1&spage=55&au=Wang%2C+Albert+Chang-hwa%3BChuang%2C+Chi-lin&isbn=&jtitle=Educational+Media+International&btitle=&rft_id=info:eric/EJ654148&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 4166ER1 4394ER1 4124ER5 4350ER5; 5696ER1 9534ER1 10411ER1 8114ER1 4605ER1 5642ER5 9453ER5 10321ER5 8043ER5 4558ER5; 5698ER1 9536ER1 9420ER1 5308ER1 5644ER5 9455ER5 9339ER5 5258ER5; 10309ER1 740ER1 10219ER5 732ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; Taiwan (Taipei)
ER  - 



TY  - JOUR
T1  - On Test and Computer Anxiety: Test Performance under CAT and SAT Conditions
AN  - 62369842; EJ626792
AB  - This study of undergraduates examined differences between computer adaptive testing (CAT) and self-adaptive testing (SAT), including feedback conditions and gender differences. Results of the Test Anxiety Inventory, Computer Anxiety Rating Scale, and a Student Attitude Questionnaire showed measurement efficiency is differentially affected by test condition and also showed significant gender effects. (Author/LRW)
JF  - Journal of Educational Computing Research
AU  - Shermis, Mark D.
AU  - Mzumara, Howard R.
AU  - Bublitz, Scott T.
Y1  - 2001
PY  - 2001
DA  - 2001
SP  - 57
EP  - 75
VL  - 24
IS  - 1
SN  - 0735-6331, 0735-6331
KW  - Computer Anxiety Scale
KW  - Test Anxiety Inventory
KW  - Self Adapted Testing
KW  - Test Anxiety Inventory (Spielberger)
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Gender Issues
KW  - Higher Education
KW  - Sex Differences
KW  - Computer Anxiety
KW  - Undergraduate Students
KW  - Computer Assisted Testing
KW  - Questionnaires
KW  - Student Attitudes
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/on-test-computer-anxiety-performance-under-cat/docview/62369842/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=On+Test+and+Computer+Anxiety%3A+Test+Performance+under+CAT+and+SAT+Conditions&title=Journal+of+Educational+Computing+Research&issn=07356331&date=2001-01-01&volume=24&issue=1&spage=57&au=Shermis%2C+Mark+D.%3BMzumara%2C+Howard+R.%3BBublitz%2C+Scott+T.&isbn=&jtitle=Journal+of+Educational+Computing+Research&btitle=&rft_id=info:eric/EJ626792&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; Computer Anxiety; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 4353ER1 4310ER5; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5; 8642ER1 6527ER1 8566ER5 6468ER5; Sex Differences; 10309ER1 740ER1 10219ER5 732ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 11231ER1 1829ER1 10411ER1 8114ER1 4605ER1 11139ER5 1815ER5 10321ER5 8043ER5 4558ER5
ER  - 



TY  - JOUR
T1  - Multidimensional Measurement from Dynamic Tests: Abstract Reasoning under Stress
AN  - 62338507; EJ625808
AB  - Discusses computerized dynamic testing with cues and items presented according to objective algorithms, elaborating on appropriate designs and psychometric models. Presents two studies involving 311 military recruits and 584 recruits that support the psychometric properties of a test measuring the susceptibility of reasoning to stressors. (SLD)
JF  - Multivariate Behavioral Research
AU  - Embretson, Susan E.
Y1  - 2000
PY  - 2000
DA  - 2000
SP  - 505
EP  - 42
VL  - 35
IS  - 4
SN  - 0027-3171, 0027-3171
KW  - Dynamic Assessment
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Stress Variables
KW  - Test Construction
KW  - Thinking Skills
KW  - Military Personnel
KW  - Computer Assisted Testing
KW  - Psychometrics
UR  - https://www.proquest.com/scholarly-journals/multidimensional-measurement-dynamic-tests/docview/62338507/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Multidimensional+Measurement+from+Dynamic+Tests%3A+Abstract+Reasoning+under+Stress&title=Multivariate+Behavioral+Research&issn=00273171&date=2000-01-01&volume=35&issue=4&spage=505&au=Embretson%2C+Susan+E.&isbn=&jtitle=Multivariate+Behavioral+Research&btitle=&rft_id=info:eric/EJ625808&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 6766ER1 4464ER1 3464ER1 5777ER1 4975ER1 9030ER1 8114ER1 4605ER1 6705ER5 4418ER5 3431ER5 5722ER5 4925ER5 8950ER5 8043ER5 4558ER5; 8530ER1 8529ER1 938ER1 9466ER1 6042ER1 8454ER5 8453ER5 929ER5 9385ER5 5983ER5; 10278ER1 10190ER5; 10895ER1 6468ER1 2820ER1 10803ER5 6409ER5 2799ER5; 10988ER1 1722ER1 2ER1 9809ER1 10896ER5 1708ER5 1ER5 9726ER5
ER  - 



TY  - JOUR
T1  - The Effects of Test Difficulty Manipulation in Computerized Adaptive Testing and Self-Adapted Testing
AN  - 62503208; EJ584930
AB  - Compared easy and difficult versions of self-adapted tests (SAT) and computerized adapted tests. No significant differences were found among the tests for estimated ability or posttest state anxiety in studies with 187 Spanish high school students, although other significant differences were found. Discusses implications for interpreting test anxiety in the SAT condition. (SLD)
JF  - Applied Measurement in Education
AU  - Ponsoda, Vicente
AU  - Olea, Julio
AU  - Rodriguez, Maria Soledad
AU  - Revuelta, Javier
Y1  - 1999
PY  - 1999
DA  - 1999
SP  - 167
EP  - 84
VL  - 12
IS  - 2
SN  - 0895-7347, 0895-7347
KW  - Spain
KW  - Self Adapted Testing
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Ability
KW  - Adaptive Testing
KW  - Comparative Analysis
KW  - Test Format
KW  - High Schools
KW  - Computer Assisted Testing
KW  - High School Students
KW  - Foreign Countries
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/effects-test-difficulty-manipulation-computerized/docview/62503208/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+Effects+of+Test+Difficulty+Manipulation+in+Computerized+Adaptive+Testing+and+Self-Adapted+Testing&title=Applied+Measurement+in+Education&issn=08957347&date=1999-01-01&volume=12&issue=2&spage=167&au=Ponsoda%2C+Vicente%3BOlea%2C+Julio%3BRodriguez%2C+Maria+Soledad%3BRevuelta%2C+Javier&isbn=&jtitle=Applied+Measurement+in+Education&btitle=&rft_id=info:eric/EJ584930&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 2ER1 1ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1980ER1 3679ER1 6663ER1 1966ER5 3643ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2883ER1 2862ER5; 4166ER1 4394ER1 4124ER5 4350ER5; 4803ER1 9534ER1 10411ER1 8114ER1 4605ER1 4755ER5 9453ER5 10321ER5 8043ER5 4558ER5; 4806ER1 9536ER1 9420ER1 5308ER1 4758ER5 9455ER5 9339ER5 5258ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10898ER1 10806ER5; Spain
ER  - 



TY  - JOUR
T1  - Performing Automatic Exams
AN  - 62477475; EJ580072
AB  - Describes a tool for building software systems which replace the role of the examiner during a typical Italian academic exam in technical/scientific subjects. Such systems are designed to exploit the advantages of self-adapted testing for reducing effects of anxiety, and of computerized adaptive testing for increasing assessment efficiency. (Author/AEF)
JF  - Computers & Education
AU  - Frosini, G.
AU  - Lazzerini, B.
AU  - Marcelloni, F.
Y1  - 1998/11//
PY  - 1998
DA  - Nov 1998
SP  - 281
EP  - 300
VL  - 31
IS  - 3
SN  - 0360-1315, 0360-1315
KW  - Italy
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Automation
KW  - Teacher Role
KW  - Foreign Countries
KW  - Science Education
KW  - Adaptive Testing
KW  - Computer Assisted Testing
KW  - Anxiety
KW  - Design Preferences
KW  - Technology Education
KW  - Computer System Design
KW  - Evaluation Methods
KW  - Computer Software Development
KW  - Testing
UR  - https://www.proquest.com/scholarly-journals/performing-automatic-exams/docview/62477475/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Performing+Automatic+Exams&title=Computers+%26+Education&issn=03601315&date=1998-11-01&volume=31&issue=3&spage=281&au=Frosini%2C+G.%3BLazzerini%2C+B.%3BMarcelloni%2C+F.&isbn=&jtitle=Computers+%26+Education&btitle=&rft_id=info:eric/EJ580072&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 554ER1 8522ER1 549ER5 8446ER5; 839ER1 10805ER1 830ER5 10713ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; Computer Software Development; 2093ER1 2799ER1 2079ER5 2780ER5; 2804ER1 8204ER1 740ER1 2785ER5 8131ER5 732ER5; 3679ER1 6663ER1 3643ER5 6603ER5; 4166ER1 4394ER1 4124ER5 4350ER5; 9442ER1 3192ER1 9361ER5 3164ER5; 10700ER1 9128ER1 10608ER5 9048ER5; 10806ER1 3192ER1 10714ER5 3164ER5; 10919ER1 6526ER1 6663ER1 10827ER5 6467ER5 6603ER5; Italy
ER  - 



TY  - JOUR
T1  - Psychometric Characteristics of Computer-Adaptive and Self-Adaptive Vocabulary Tests: The Role of Answer Feedback and Test Anxiety
AN  - 62381803; EJ590595
AB  - Studied effects of administration mode [computer adaptive test (CAT) versus self-adaptive test (SAT)], item-by-item answer feedback, and test anxiety on results from computerized vocabulary tests taken by 293 college students. CATs were more reliable than SATs, and administration time was less when feedback was provided. (SLD)
JF  - Journal of Educational Measurement
AU  - Vispoel, Walter P.
Y1  - 1998///Jul 1998 - Sep
PY  - 1998
DA  - Jul 1998 - Sep 1998
SP  - 155
EP  - 67
VL  - 35
IS  - 2
SN  - 0022-0655, 0022-0655
KW  - Self Adapted Testing
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Vocabulary
KW  - Higher Education
KW  - College Students
KW  - Feedback
KW  - Computer Assisted Testing
KW  - Psychometrics
KW  - Test Items
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/psychometric-characteristics-computer-adaptive/docview/62381803/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Psychometric+Characteristics+of+Computer-Adaptive+and+Self-Adaptive+Vocabulary+Tests%3A+The+Role+of+Answer+Feedback+and+Test+Anxiety&title=Journal+of+Educational+Measurement&issn=00220655&date=1998-07-01&volume=35&issue=2&spage=155&au=Vispoel%2C+Walter+P.&isbn=&jtitle=Journal+of+Educational+Measurement&btitle=&rft_id=info:eric/EJ590595&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1829ER1 10411ER1 8114ER1 4605ER1 1815ER5 10321ER5 8043ER5 4558ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; Feedback; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5; 8530ER1 8529ER1 938ER1 9466ER1 6042ER1 8454ER5 8453ER5 929ER5 9385ER5 5983ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10900ER1 10808ER5; 11467ER1 11371ER5
ER  - 



TY  - RPRT
T1  - Comparing Restricted and Unrestricted Self-Adapted Testing as Alternatives to Computerized Adaptive Testing
AN  - 62449718; ED423258
AB  - Previous studies have shown that, when administered a self-adapted test, a few examinees will choose item difficulty levels that are not well-matched to their proficiencies, resulting in high standard errors of proficiency estimation. This study investigated whether the previously observed effects of a self-adapted test--lower anxiety and higher test performance relative to a computerized adaptive test (CAT)--can be sustained while eliminating the high standard errors. A restricted self-adapted test (RS-AT) in which examinees were allowed to choose among a set of difficulty levels only in the region of their proficiency estimates was utilized in this study. Data were collected from 273 students in an introductory statistics class. The results show that while the RS-AT effectively controlled the standard errors of proficiency estimation, examinees receiving an RS-AT did not show higher mean proficiency or lower posttest state anxiety than examinees receiving a CAT. (Contains 3 tables and 15 references.) (SLD)
AU  - Roos, Linda L.
AU  - Wise, Steven L.
AU  - Finney, Sara J.
Y1  - 1998/04//
PY  - 1998
DA  - Apr 1998
SP  - 1
EP  - 22
KW  - Restricted Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Adaptive Testing
KW  - Performance Factors
KW  - Comparative Analysis
KW  - Higher Education
KW  - College Students
KW  - Error of Measurement
KW  - Computer Assisted Testing
KW  - Selection
KW  - Test Items
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/comparing-restricted-unrestricted-self-adapted/docview/62449718/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Comparing+Restricted+and+Unrestricted+Self-Adapted+Testing+as+Alternatives+to+Computerized+Adaptive+Testing&issn=&date=1998-04-01&volume=&issue=&spage=1&au=Roos%2C+Linda+L.%3BWise%2C+Steven+L.%3BFinney%2C+Sara+J.&isbn=&jtitle=&btitle=Comparing+Restricted+and+Unrestricted+Self-Adapted+Testing+as+Alternatives+to+Computerized+Adaptive+Testing&rft_id=info:eric/ED423258&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - An Investigation of Self-Adapted Testing in a Spanish High School Population
AN  - 62625623; EJ545463
AB  - A study involving 209 Spanish high school students compared computer-based English vocabulary tests: (1) a self-adapted test (SAT); (2) a computerized adaptive test (CAT); (3) a conventional test; and (4) a test combining SAT and CAT. No statistically significant differences were found among test types for estimated ability or posttest anxiety. (SLD)
JF  - Educational and Psychological Measurement
AU  - Ponsoda, Vincente
AU  - And Others
Y1  - 1997/04//
PY  - 1997
DA  - Apr 1997
SP  - 210
EP  - 21
KW  - Spain
KW  - Self Adapted Testing
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Ability
KW  - Adaptive Testing
KW  - Comparative Analysis
KW  - Test Format
KW  - English (Second Language)
KW  - High Schools
KW  - Computer Assisted Testing
KW  - High School Students
KW  - Anxiety
KW  - Foreign Countries
UR  - https://www.proquest.com/reports/investigation-self-adapted-testing-spanish-high/docview/62625623/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=An+Investigation+of+Self-Adapted+Testing+in+a+Spanish+High+School+Population&title=Educational+and+Psychological+Measurement&issn=00131644&date=1997-04-01&volume=57&issue=2&spage=210&au=Ponsoda%2C+Vincente%3BAnd+Others&isbn=&jtitle=Educational+and+Psychological+Measurement&btitle=&rft_id=info:eric/EJ545463&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - Overview of Practical Issues in a CAT Program
AN  - 62624506; ED408330
AB  - Computerized adaptive testing (CAT) has become increasingly common in large-scale testing programs. This paper considers relevant practical issues that are likely to be faced by the developers and managers of a CAT program. The first cluster of issues is that of item pool development and maintenance. It includes such considerations as item pool specifications, the choice of item response theory model, and other concerns in constructing and choosing test items. The second cluster of items involves administering and scoring the CAT. Proficiency estimation method, test items, item review, and equating CAT scores to paper-and-pencil tests are areas that must be considered. The third cluster involves protecting the integrity of the CAT item pool, considering security and coaching concerns. A fourth cluster includes issues involving examinees. These issues (whether or not to allow item review, how to set time limits, how to address examinee anxiety, test taker motivation, and test equity) are areas that must be explored for fair and useful tests. (SLD)
AU  - Wise, Steven L.
Y1  - 1997/03//
PY  - 1997
DA  - Mar 1997
SP  - 1
EP  - 8
KW  - Large Scale Assessment
KW  - ERIC, Resources in Education (RIE)
KW  - Equated Scores
KW  - Timed Tests
KW  - Scoring
KW  - Student Attitudes
KW  - Computer Attitudes
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Test Construction
KW  - Testing Problems
KW  - Computer Assisted Testing
KW  - Item Banks
KW  - Review (Reexamination)
KW  - Test Items
KW  - Equal Education
KW  - Item Response Theory
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/overview-practical-issues-cat-program/docview/62624506/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=unknown&sid=ProQ:ProQ%3Aeric&atitle=Overview+of+Practical+Issues+in+a+CAT+Program&title=Undefined&issn=&date=1997-03-01&volume=&issue=&spage=1&au=Wise%2C+Steven+L.&isbn=&jtitle=Undefined&btitle=&rft_id=info:eric/ED408330&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2044ER1 740ER1 2030ER5 732ER5; 3589ER1 1586ER1 3192ER1 3554ER5 1573ER5 3164ER5; 3599ER1 9485ER1 2602ER1 3564ER5 9404ER5 2584ER5; 5593ER1 5540ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 9086ER1 128ER1 9006ER5 126ER5; 9486ER1 6520ER1 9405ER5 6461ER5; 10309ER1 740ER1 10219ER5 732ER5; 10358ER1 6915ER1 10268ER5 6852ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10895ER1 6468ER1 2820ER1 10803ER5 6409ER5 2799ER5; 10900ER1 10808ER5; 10922ER1 8339ER1 10830ER5 8264ER5; 11010ER1 10925ER1 6527ER1 10918ER5 10833ER5 6468ER5
ER  - 



TY  - RPRT
T1  - Examinee Issues in CAT
AN  - 62603310; ED408329
AB  - The perspective of the examinee during the administration of a computerized adaptive test (CAT) is discussed, focusing on issues of test development. Item review is the first issue discussed. Virtually no CATs provide the opportunity for the examinee to go back and review, and possibly change, answers. There are arguments on either side of the item review issue, and test givers should weigh them carefully, considering examinee anxiety and performance factors. Another issue is that of time limits, which have little benefit for test takers, but serve only the interests of test givers. CAT developers should consider very liberal time limits or none at all, especially since a CAT is shorter than its conventional testing counterparts. Test anxiety may be increased in a CAT environment, and test developers should be aware of the potential for anxiety among examinees. Another issue is that of examinee motivation. CAT developers should be aware of the effects of test consequences on test performance to ensure that data used to calibrate item banks are collected under conditions that have the same consequences as the operational test. Equity is an important issue in CAT, since some examinees will have less computer experience than others. Each of these issues has implications for the validity of inferences made from CAT scores and should be considered when CATs are used. (Contains 27 references.) (SLD)
AU  - Wise, Steven L.
Y1  - 1997/03//
PY  - 1997
DA  - Mar 1997
SP  - 1
EP  - 17
KW  - Calibration
KW  - ERIC, Resources in Education (RIE)
KW  - Timed Tests
KW  - Student Attitudes
KW  - Computer Attitudes
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Test Construction
KW  - Testing Problems
KW  - Computer Assisted Testing
KW  - Item Banks
KW  - Review (Reexamination)
KW  - Test Items
KW  - Equal Education
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/examinee-issues-cat/docview/62603310/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Examinee+Issues+in+CAT&issn=&date=1997-03-01&volume=&issue=&spage=1&au=Wise%2C+Steven+L.&isbn=&jtitle=&btitle=Examinee+Issues+in+CAT&rft_id=info:eric/ED408329&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - BASC: Basic Assessment System for Children
AN  - 62599931; EJ532033
AB  - The Behavior Assessment System for Children (BASC), which was designed to assess both children's and adolescents' emotional disorders, personality constructs, and behavior problems, is discussed. Discusses the BASC technical manual, and psychometric properties such as norms, reliability, and validity. Offers favorable commentary for the BASC. (KW)
JF  - Measurement and Evaluation in Counseling and Development
AU  - Merenda, Peter F.
Y1  - 1996/01//
PY  - 1996
DA  - Jan 1996
SP  - 229
EP  - 32
VL  - 28
IS  - 4
SN  - 0748-1756, 0748-1756
KW  - Behavior Assessment System for Children
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Emotional Disturbances
KW  - Evaluation
KW  - Evaluation Problems
KW  - Behavior Problems
KW  - Mental Disorders
KW  - Psychometrics
KW  - Self Evaluation (Individuals)
KW  - Children
KW  - Evaluation Methods
KW  - Evaluation Research
UR  - https://www.proquest.com/scholarly-journals/basc-basic-assessment-system-children/docview/62599931/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=BASC%3A+Basic+Assessment+System+for+Children&title=Measurement+and+Evaluation+in+Counseling+and+Development&issn=07481756&date=1996-01-01&volume=28&issue=4&spage=229&au=Merenda%2C+Peter+F.&isbn=&jtitle=Measurement+and+Evaluation+in+Counseling+and+Development&btitle=&rft_id=info:eric/EJ532033&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 928ER1 8339ER1 919ER5 8264ER5; 1491ER1 321ER1 8114ER1 4605ER1 1480ER5 318ER5 8043ER5 4558ER5; 3433ER1 6611ER1 2911ER1 3401ER5 6552ER5 2890ER5; 3676ER1 3640ER5; 3679ER1 6663ER1 3643ER5 6603ER5; 3681ER1 8339ER1 3645ER5 8264ER5; 3683ER1 6665ER1 8947ER1 3647ER5 6605ER5 8868ER5; 6611ER1 2911ER1 6552ER5 2890ER5; 8530ER1 8529ER1 938ER1 9466ER1 6042ER1 8454ER5 8453ER5 929ER5 9385ER5 5983ER5; 9587ER1 3676ER1 9506ER5 3640ER5
ER  - 



TY  - RPRT
T1  - Effects of Informed Item Selection on Test Performance and Anxiety for Examinees Administered a Self-Adapted Test
AN  - 62663353; EJ514249
AB  - No significant differences in performance on a self-adapted test or anxiety were found for college students (n=218) taking a self-adapted test who selected item difficulty without any prior information, inspected an item before selecting, or answered a typical item and received performance feedback. (SLD)
JF  - Educational and Psychological Measurement
AU  - Plake, Barbara S.
AU  - And Others
Y1  - 1995/10//
PY  - 1995
DA  - Oct 1995
SP  - 736
EP  - 42
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Higher Education
KW  - Selection
KW  - Adaptive Testing
KW  - Knowledge Level
KW  - College Students
KW  - Feedback
KW  - Computer Assisted Testing
KW  - Test Items
KW  - Achievement
KW  - Performance
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/effects-informed-item-selection-on-test/docview/62663353/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Effects+of+Informed+Item+Selection+on+Test+Performance+and+Anxiety+for+Examinees+Administered+a+Self-Adapted+Test&title=Educational+and+Psychological+Measurement&issn=00131644&date=1995-10-01&volume=55&issue=5&spage=736&au=Plake%2C+Barbara+S.%3BAnd+Others&isbn=&jtitle=Educational+and+Psychological+Measurement&btitle=&rft_id=info:eric/EJ514249&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - The Influence of Examinee Test-Taking Motivation in Computerized Adaptive Testing
AN  - 62656885; ED392839
AB  - The purpose of the study was to investigate the effects of test motivation on estimated ability, test anxiety, and attitudes toward computerized adaptive testing (CAT). Korean college students (n=208) were given the Math Aptitude Test, Math Self-Concept Scale, Math Test Anxiety Scale, Computer Competence Instrument, Computer Anxiety Scale, and Test Anxiety Inventory in the regular classroom. The two groups (motivated and non-motivated) were randomly assigned by each course section. The motivated group was given special test instructions. The paper-and-pencil test (PPT) and the CAT algebra tests were given to each group in random order (PPT-CAT or CAT-PPT) under the counterbalanced design at the computer laboratory. They were also given a 10-item paper test anxiety scale, a 10-item computer test anxiety scale, and a paper-and-pencil version of the Questionnaire on Computerized Adaptive Testing. A multivariate analysis of covariance, with the math aptitude and the test anxiety as covariates, demonstrated that test motivation influenced improvement in estimated ability and reduction in test anxiety, but did not affect CAT attitudes. (Contains 4 tables and 45 references.) (Author)
AU  - Kim, JinGyu
AU  - McLean, James E.
Y1  - 1995/04//
PY  - 1995
DA  - Apr 1995
SP  - 1
EP  - 22
KW  - South Korea
KW  - Koreans
KW  - Paper and Pencil Tests
KW  - Korea
KW  - ERIC, Resources in Education (RIE)
KW  - Ability
KW  - Multivariate Analysis
KW  - Higher Education
KW  - Student Attitudes
KW  - Foreign Countries
KW  - Adaptive Testing
KW  - Student Motivation
KW  - College Students
KW  - Self Concept
KW  - Aptitude Tests
KW  - Computer Assisted Testing
KW  - Mathematics Achievement
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/influence-examinee-test-taking-motivation/docview/62656885/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=The+Influence+of+Examinee+Test-Taking+Motivation+in+Computerized+Adaptive+Testing&issn=&date=1995-04-01&volume=&issue=&spage=1&au=Kim%2C+JinGyu%3BMcLean%2C+James+E.&isbn=&jtitle=&btitle=The+Influence+of+Examinee+Test-Taking+Motivation+in+Computerized+Adaptive+Testing&rft_id=info:eric/ED392839&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - THES
T1  - The effects of computerized adaptive testing and examinee test motivation on algebra skills, test anxiety, and attitudes
AN  - 304160034
AB  - The major purpose of the study was to investigate the effects of test method and test motivation on estimated ability, test anxiety, and attitudes toward computerized adaptive testing (CAT). This research also examined the relationships between examinees' individual difference variables and computerized adaptive test performance.    Korean college students (n = 208) were given the Math Aptitude Test, Math Self-Concept Scale, Math Test Anxiety Scale, Computer Competence Instrument, Computer Anxiety Scale, and Test Anxiety Inventory in the regular classroom. The two groups (Motivated and Non-motivated) were randomly assigned by each course section. The motivated group was given special test instructions. The paper-and-pencil test (PPT) and the CAT algebra tests were given to each group in random order (PPT-CAT or CAT-PPT) at the computer laboratory. Students were given a 10-item paper test anxiety scale after taking the PPT, and a 10-item computer test anxiety scale after taking the CAT. Finally, they were given a paper-and-pencil version of the Questionnaire on Computerized Adaptive Testing and Computer Experience Questionnaire. The examinees' test motivation was the independent variable in a multivariate analysis of covariance (MANCOVA). The six dependent variables were two estimated algebra skills (PPT and CAT), two test anxiety scores (PPT and CAT), and two CAT attitudes scores. The covariates were the math aptitude and the test anxiety variables.    This study demonstrated the equivalence between the PPT and the CAT and found that test motivation influenced improvement in estimated ability and reduction in test anxiety, but did not affect CAT attitudes. It was found that math aptitude and test motivation variables could be the most significant predictors of computerized adaptive test performance.    The findings suggest that test motivation is an important factor to help explain students' achievement. Further research should focus on how to enhance students' motivation in classroom learning as well as on tests.
JF  - ProQuest Dissertations and Theses
AU  - Kim, Jingyu
A3  - McLean, James E.
Y1  - 1995
PY  - 1995
DA  - 1995
SP  - 122
CY  - United States -- Alabama
PB  - The University of Alabama
PP  - United States -- Alabama
SN  - 979-8-209-25055-5
KW  - Education
KW  - examinees
KW  - Educational evaluation
KW  - Educational technology
KW  - 0710:Educational technology
KW  - 0288:Educational tests & measurements
UR  - https://www.proquest.com/dissertations-theses/effects-computerized-adaptive-testing-examinee/docview/304160034/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=The+effects+of+computerized+adaptive+testing+and+examinee+test+motivation+on+algebra+skills%2C+test+anxiety%2C+and+attitudes&issn=&date=1995-01-01&volume=&issue=&spage=&au=Kim%2C+Jingyu&isbn=979-8-209-25055-5&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2022-02-28
M3  - Ph.D.
M1  - 9535884
ER  - 



TY  - JOUR
T1  - The Psychological Impacts of Computerized Adaptive Testing Methods
AN  - 62724750; EJ491540
AB  - Discussion of computerized adaptive testing focuses on a study of graduate students at Indiana University at Bloomington that examined three kinds of computerized adaptive testing procedures to determine their psychological impact and how they may affect test performance. Previous research is reviewed, and further research is suggested. (28 references) (LRW)
JF  - Educational Technology
AU  - Powell, Zen-Hsiu Emily
Y1  - 1994/10//
PY  - 1994
DA  - Oct 1994
SP  - 41
EP  - 47
VL  - 34
IS  - 8
SN  - 0013-1962, 0013-1962
KW  - Psychological Influences
KW  - Indiana University Bloomington
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Correlation
KW  - Higher Education
KW  - Test Results
KW  - Hypothesis Testing
KW  - Adaptive Testing
KW  - Graduate Students
KW  - Analysis of Variance
KW  - Computer Assisted Testing
KW  - Academic Achievement
KW  - Literature Reviews
KW  - Research Needs
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/psychological-impacts-computerized-adaptive/docview/62724750/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+Psychological+Impacts+of+Computerized+Adaptive+Testing+Methods&title=Educational+Technology&issn=00131962&date=1994-10-01&volume=34&issue=8&spage=41&au=Powell%2C+Zen-Hsiu+Emily&isbn=&jtitle=Educational+Technology&btitle=&rft_id=info:eric/EJ491540&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 29ER1 98ER1 28ER5 96ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; Analysis of Variance; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2295ER1 10210ER1 2604ER1 3679ER1 6663ER1 2278ER5 10125ER5 2586ER5 3643ER5 6603ER5; 4514ER1 1829ER1 10411ER1 8114ER1 4605ER1 4467ER5 1815ER5 10321ER5 8043ER5 4558ER5; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5; 5012ER1 3679ER1 6663ER1 4962ER5 3643ER5 6603ER5; 6202ER1 8584ER1 6143ER5 8508ER5; 8965ER1 7085ER1 8886ER5 7022ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10906ER1 10814ER5
ER  - 



TY  - RPRT
T1  - Effects of Informed Item Selection on Test Performance and Anxiety for Examinees Administered a Self-Adapted Test
AN  - 62809013; ED372075
AB  - In self-adapted testing (SAT), examinees select the difficulty level of items administered. This study investigated three variations of prior information provided when taking an SAT: (1) no information (examinees selected item difficulty levels without prior information); (2) view (examinees inspected a typical item from each difficulty level prior to taking the SAT); and (3) route (examinees answered a typical item from each difficulty level and were informed prior to the SAT of the level that best matched their performance). Subjects were 218 students in an introductory statistics course, 85 percent of whom were undergraduates. No significant differences in test performance or anxiety were found as a function of providing examinees more information. Four tables are included. (Contains 9 references.) (Author/SLD)
AU  - Plake, Barbara S.
AU  - And Others
Y1  - 1994/04//
PY  - 1994
DA  - Apr 1994
SP  - 1
EP  - 17
KW  - Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Adaptive Testing
KW  - Graduate Students
KW  - Higher Education
KW  - Knowledge Level
KW  - College Students
KW  - Computer Assisted Testing
KW  - Selection
KW  - Test Items
KW  - Performance
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/effects-informed-item-selection-on-test/docview/62809013/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Effects+of+Informed+Item+Selection+on+Test+Performance+and+Anxiety+for+Examinees+Administered+a+Self-Adapted+Test&issn=&date=1994-04-01&volume=&issue=&spage=1&au=Plake%2C+Barbara+S.%3BAnd+Others&isbn=&jtitle=&btitle=Effects+of+Informed+Item+Selection+on+Test+Performance+and+Anxiety+for+Examinees+Administered+a+Self-Adapted+Test&rft_id=info:eric/ED372075&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - Comparing Computerized Adaptive and Self-Adapted Tests: The Influence of Examinee Achievement Locus of Control
AN  - 62798906; ED371007
AB  - This study investigated the relationship between examinee achievement-specific locus of control and the differences between self-adapted testing (SAT) and computerized adaptive testing (CAT) in terms of mean estimated proficiency and posttest state anxiety. Subjects were 379 college students. A disordinal interaction was found between test type and locus of control. Examinees with an internal locus of control were affected positively by the SAT (relative to the CAT). For examinees with an external locus of control, however, the SAT appeared to have a negative effect on both estimated proficiency and posttest state anxiety. There are four tables and two figures. (Contains 18 references.) (Author/SLD)
AU  - Wise, Steven L.
AU  - And Others
Y1  - 1994/04//
PY  - 1994
DA  - Apr 1994
SP  - 1
EP  - 22
KW  - Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Personal Autonomy
KW  - Pretests Posttests
KW  - Adaptive Testing
KW  - Attribution Theory
KW  - Comparative Analysis
KW  - College Students
KW  - Self Concept
KW  - Computer Assisted Testing
KW  - Academic Achievement
KW  - Anxiety
KW  - Locus of Control
UR  - https://www.proquest.com/reports/comparing-computerized-adaptive-self-adapted/docview/62798906/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Comparing+Computerized+Adaptive+and+Self-Adapted+Tests%3A+The+Influence+of+Examinee+Achievement+Locus+of+Control&issn=&date=1994-04-01&volume=&issue=&spage=1&au=Wise%2C+Steven+L.%3BAnd+Others&isbn=&jtitle=&btitle=Comparing+Computerized+Adaptive+and+Self-Adapted+Tests%3A+The+Influence+of+Examinee+Achievement+Locus+of+Control&rft_id=info:eric/ED371007&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - Computerized Adaptive Testing Exploring Examinee Response Time Using Hierarchical Linear Modeling
AN  - 62566300; ED400287
AB  - Examinee response times from a computerized adaptive test taken by 204 examinees taking a certification examination were analyzed using a hierarchical linear model. Two equations were posed: a within-person model and a between-person model. Variance within persons was eight times greater than variance between persons. Several variables significantly predicted within-person variance. Response time increased with increasing items, test length, and increasing relative item difficulty. Item sequence was negatively related to response time, and some content areas required more time than others. Examinees spent more time on items they got wrong than on items they got right, and they took longer to respond when the correct answer was A, B, or C than when the correct answer was D. Only one variable, test anxiety, significantly predicted variance between examinees. Examinee age, sex, first language, and ethnicity did not predict between-person variance, and low-ability examinees did not take longer to respond to items than high-ability examinees. Understanding how item characteristics impact on response time may allow test developers to allot total test time based on the response time history of the individual test items. This study also suggests that examinee characteristics are generally not related to response time, but that more controllable factors such as item length, position of the keyed correct answer, and use of figures do contribute to response items. An appendix contains the anxiety survey. (Contains 1 figure, 5 tables, and 12 references.) (Author/SLD)
AU  - Bergstrom, Betty
AU  - And Others
Y1  - 1994/04//
PY  - 1994
DA  - Apr 1994
SP  - 1
EP  - 26
KW  - Hierarchical Linear Modeling
KW  - ERIC, Resources in Education (RIE)
KW  - Student Characteristics
KW  - Timed Tests
KW  - Reaction Time
KW  - Certification
KW  - Responses
KW  - Adaptive Testing
KW  - Test Length
KW  - Test Construction
KW  - Computer Assisted Testing
KW  - Adults
KW  - Test Items
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/computerized-adaptive-testing-exploring-examinee/docview/62566300/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Computerized+Adaptive+Testing+Exploring+Examinee+Response+Time+Using+Hierarchical+Linear+Modeling&issn=&date=1994-04-01&volume=&issue=&spage=1&au=Bergstrom%2C+Betty%3BAnd+Others&isbn=&jtitle=&btitle=Computerized+Adaptive+Testing+Exploring+Examinee+Response+Time+Using+Hierarchical+Linear+Modeling&rft_id=info:eric/ED400287&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - Understanding Self-Adapted Testing: The Perceived Control Hypothesis
AN  - 62817989; EJ484371
AB  - This article summarizes prior research findings on self-adapted testing (SAT) and examines the hypothesis that positive effects from SAT are the result of examinees perceiving greater control over the testing situation, which may lead to reduced test anxiety and improved performance. Prior research on perceived control is also discussed. (SLD)
JF  - Applied Measurement in Education
AU  - Wise, Stephen L.
Y1  - 1994
PY  - 1994
DA  - 1994
SP  - 15
EP  - 24
VL  - 7
IS  - 1
SN  - 0895-7347, 0895-7347
KW  - Self Adapted Testing
KW  - Testing Effects
KW  - Perceived Control
KW  - Self Monitoring
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Cognitive Processes
KW  - Educational Research
KW  - Test Construction
KW  - Computer Assisted Testing
KW  - Literature Reviews
KW  - Student Attitudes
KW  - Performance
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/understanding-self-adapted-testing-perceived/docview/62817989/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Understanding+Self-Adapted+Testing%3A+The+Perceived+Control+Hypothesis&title=Applied+Measurement+in+Education&issn=08957347&date=1994-01-01&volume=7&issue=1&spage=15&au=Wise%2C+Stephen+L.&isbn=&jtitle=Applied+Measurement+in+Education&btitle=&rft_id=info:eric/EJ484371&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1733ER1 1719ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 3298ER1 8947ER1 3269ER5 8868ER5; 6202ER1 8584ER1 6143ER5 8508ER5; 7798ER1 921ER1 7728ER5 912ER5; 10309ER1 740ER1 10219ER5 732ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10895ER1 6468ER1 2820ER1 10803ER5 6409ER5 2799ER5
ER  - 



TY  - RPRT
T1  - Computerized-Adaptive and Self-Adapted Music-Listening Tests: Psychometric Features and Motivational Benefits
AN  - 62817433; EJ484372
AB  - Computerized-adaptive (CAT) and self-adapted (SAT) music listening tests were compared for efficiency, reliability, validity, and motivational benefits with 53 junior high school students. Results demonstrate trade-offs, with greater potential motivational benefits for SAT and greater efficiency for CAT. SAT elicited more favorable responses from examinees. (SLD)
JF  - Applied Measurement in Education
AU  - Vispoel, Walter P.
AU  - Coffman, Don D.
Y1  - 1994
PY  - 1994
DA  - 1994
SP  - 25
EP  - 51
KW  - Precision (Mathematics)
KW  - Self Adapted Testing
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Test Reliability
KW  - Psychometrics
KW  - Student Attitudes
KW  - Test Validity
KW  - Junior High School Students
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Test Construction
KW  - Junior High Schools
KW  - Efficiency
KW  - Listening
KW  - Computer Assisted Testing
KW  - Music
KW  - Item Response Theory
UR  - https://www.proquest.com/reports/computerized-adaptive-self-adapted-music/docview/62817433/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Computerized-Adaptive+and+Self-Adapted+Music-Listening+Tests%3A+Psychometric+Features+and+Motivational+Benefits&title=Applied+Measurement+in+Education&issn=08957347&date=1994-01-01&volume=7&issue=1&spage=25&au=Vispoel%2C+Walter+P.%3BCoffman%2C+Don+D.&isbn=&jtitle=Applied+Measurement+in+Education&btitle=&rft_id=info:eric/EJ484372&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - The Relationship between Examinee Anxiety and Preference for Self-Adapted Testing
AN  - 62817395; EJ484374
AB  - The hypothesis that previously found effects of self-adapted testing (SAT) are attributable to examinees' having an increased perception of control over a stressful testing situation was studied with 377 college students who took computerized adaptive tests or SAT. The strongest preference for SAT was seen in individuals with the highest mathematics anxiety. (SLD)
JF  - Applied Measurement in Education
AU  - Wise, Steven L.
AU  - And Others
Y1  - 1994
PY  - 1994
DA  - 1994
SP  - 81
EP  - 91
KW  - Perceived Control
KW  - Self Adapted Testing
KW  - Preference Data
KW  - Testing Effects
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Mathematics Anxiety
KW  - Higher Education
KW  - College Students
KW  - Computer Assisted Testing
KW  - Student Attitudes
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/relationship-between-examinee-anxiety-preference/docview/62817395/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+Relationship+between+Examinee+Anxiety+and+Preference+for+Self-Adapted+Testing&title=Applied+Measurement+in+Education&issn=08957347&date=1994-01-01&volume=7&issue=1&spage=81&au=Wise%2C+Steven+L.%3BAnd+Others&isbn=&jtitle=Applied+Measurement+in+Education&btitle=&rft_id=info:eric/EJ484374&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - Individual Differences in Computerized Adaptive Testing
AN  - 62803573; ED365713
AB  - Research on the major computerized adaptive testing (CAT) strategies is reviewed, and some findings are reported that examine effects of examinee demographic and psychological characteristics on CAT strategies. In fixed branching strategies, all examinees respond to a common routing test, the score of which is used to assign examinees to a second-stage test. The currently popular statistically branched adaptive strategies are based on item-response theory, and include maximum likelihood strategy and Bayesian strategy. Two alternative strategies are the use of self-adapted testing and testlet strategies. Examinee characteristic variables are divided into: (1) demographic variables; (2) computer-use variables; (3) test-taking strategy variables; (4) cognitive characteristics; and (5) affective characteristics. Although research on the relationship between examinee psychological characteristics and CAT has been inconclusive, the basic findings are that examinees of different ethnic, gender, age, grade, ability, academic self-concept, test anxiety, computer anxiety, math anxiety, and computer experience groups are differentially affected by the adaptive testing strategies. Implications for research and practice are discussed. (Contains 67 references.) (SLD)
AU  - Kim, JinGyu
Y1  - 1993/11//
PY  - 1993
DA  - Nov 1993
SP  - 1
EP  - 22
KW  - Self Adapted Testing
KW  - Academic Self Concept
KW  - Testlets
KW  - ERIC, Resources in Education (RIE)
KW  - Ability
KW  - Cognitive Processes
KW  - Demography
KW  - Sex Differences
KW  - Student Characteristics
KW  - Age Differences
KW  - Bayesian Statistics
KW  - Affective Behavior
KW  - Individual Differences
KW  - Adaptive Testing
KW  - Mathematics Anxiety
KW  - Ethnic Groups
KW  - Test Wiseness
KW  - Computer Assisted Testing
KW  - Psychological Characteristics
KW  - Test Items
KW  - Computer Literacy
KW  - Maximum Likelihood Statistics
KW  - Item Response Theory
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/individual-differences-computerized-adaptive/docview/62803573/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=unknown&sid=ProQ:ProQ%3Aeric&atitle=Individual+Differences+in+Computerized+Adaptive+Testing&title=Undefined&issn=&date=1993-11-01&volume=&issue=&spage=1&au=Kim%2C+JinGyu&isbn=&jtitle=Undefined&btitle=&rft_id=info:eric/ED365713&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 2ER1 1ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 269ER1 921ER1 266ER5 912ER5; 317ER1 5121ER1 2875ER1 314ER5 5071ER5 2854ER5; 907ER1 10210ER1 2604ER1 3679ER1 6663ER1 10226ER1 6490ER1 6042ER1 898ER5 10140ER5 6431ER5 5983ER5 10125ER5 2586ER5 3643ER5 6603ER5; 1733ER1 1719ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2066ER1 10801ER1 6964ER1 2052ER5 10709ER5; 2731ER1 9926ER1 9466ER1 6042ER1 2712ER5 9842ER5 9385ER5 5983ER5; 3652ER1 8114ER1 4605ER1 3616ER5 8043ER5 4558ER5; 5121ER1 2875ER1 5071ER5 2854ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 6493ER1 554ER1 8522ER1 6434ER5 549ER5 8446ER5; 6515ER1 10210ER1 2604ER1 3679ER1 6663ER1 10226ER1 6490ER1 6042ER1 6456ER5 10140ER5 6431ER5 5983ER5 10125ER5 2586ER5 3643ER5 6603ER5; 8516ER1 5118ER1 8440ER5 5068ER5; Sex Differences; 10319ER1 10229ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10900ER1 10808ER5; 10918ER1 10826ER5
ER  - 



TY  - RPRT
T1  - An Investigation of Restricted Self-Adapted Testing
AN  - 62872992; ED358153
AB  - A new testing strategy that provides protection against the problem of having examinees in adaptive testing choose difficulty levels that are not matched to their proficiency levels was introduced and evaluated. The method, termed restricted self-adapted testing (RSAT), still provides examinees with a degree of control over the difficulty levels of their test items. The range of item choice is restricted to a region around the examinee's current proficiency estimate. Participants in this study were 186 students in grades 3 through 8 in the Portland (Oregon) Public School system during the winter of 1992-93, who were tested as part of an ongoing computerized adaptive testing program. Students were randomly assigned to a computerized adaptive test (CAT), a self-adaptive test (SADT), or RSAT in mathematics. Results indicate no differences between CAT and SADT conditions in terms of mean proficiency and mean posttest state anxiety. The basic RSAT method appears to hold promise for providing examinees with control over the testing situation, while preventing large mismatches between item difficulty choice and proficiency level. The RSAT procedure should be evaluated empirically. (SLD)
AU  - Wise, Steven L.
AU  - And Others
Y1  - 1993/04//
PY  - 1993
DA  - Apr 1993
SP  - 1
EP  - 13
KW  - Portland School District OR
KW  - Restricted Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Elementary School Students
KW  - Achievement Tests
KW  - Selection
KW  - Elementary Education
KW  - Pretests Posttests
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Mathematics Tests
KW  - Testing Problems
KW  - Computer Assisted Testing
KW  - Test Items
KW  - Difficulty Level
KW  - Mathematics Achievement
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/investigation-restricted-self-adapted-testing/docview/62872992/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=An+Investigation+of+Restricted+Self-Adapted+Testing&issn=&date=1993-04-01&volume=&issue=&spage=1&au=Wise%2C+Steven+L.%3BAnd+Others&isbn=&jtitle=&btitle=An+Investigation+of+Restricted+Self-Adapted+Testing&rft_id=info:eric/ED358153&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - The Role of Anxiety in Examinee Preference for Self-Adapted Testing
AN  - 62867202; ED358154
AB  - This study assessed whether providing examinees with a choice between computerized adaptive testing (CAT) and self-adaptive testing (SAT) affects test performance in comparison with being assigned a CAT or SAT, and evaluated variables influencing examinee choice of either test form. The relative influences of test type and test choice on examinee anxiety were also examined. Subjects were 244 undergraduate and 133 graduate students from a large midwestern university. Students were randomly assigned to SAT, CAT, and choice conditions for an algebra test. Test-related anxiety was assessed with a paper-and-pencil measure in pretests and posttests. It was found that, for students with high mathematics anxiety, providing a choice between CAT and SAT led to significantly higher mean proficiency estimates, lending support to the hypothesis that examinees can cope with a stressful situation more effectively if they feel that they have some control over the source of the stress. Expected differences in estimated proficiency and posttest state anxiety between CAT and SAT conditions were not found, but a strong relationship was seen between examinee test type choice and mathematics anxiety level. Higher anxiety examinees have a greater preference for the control provided by SAT. Six tables and two graphs summarize findings. (SLD)
AU  - Wise, Steven L.
AU  - And Others
Y1  - 1993/04//
PY  - 1993
DA  - Apr 1993
SP  - 1
EP  - 18
KW  - Preference Patterns
KW  - Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Ability
KW  - Test Selection
KW  - Higher Education
KW  - Student Attitudes
KW  - Pretests Posttests
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Mathematics Anxiety
KW  - Algebra
KW  - Test Format
KW  - College Students
KW  - Mathematics Tests
KW  - Computer Assisted Testing
KW  - Mathematics Achievement
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/role-anxiety-examinee-preference-self-adapted/docview/62867202/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=The+Role+of+Anxiety+in+Examinee+Preference+for+Self-Adapted+Testing&issn=&date=1993-04-01&volume=&issue=&spage=1&au=Wise%2C+Steven+L.%3BAnd+Others&isbn=&jtitle=&btitle=The+Role+of+Anxiety+in+Examinee+Preference+for+Self-Adapted+Testing&rft_id=info:eric/ED358154&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - THES
T1  - Effects of computerized adaptive test anxiety on nursing licensure examination
AN  - 304041739
AB  - Purpose of study. This study was to determine if nursing candidates for licensure experienced an increase in anxiety due to the administration of an examination by computerized adaptive testing (CAT). A second purpose was to discover if certain groups were "at risk" of experiencing computer test anxiety.    Method. This study was a two-group, experimental design conducted concurrently with the CAT-NCLEX simulation. The National Council of State Boards of Nursing selected practical nursing graduates and repeat examinees to participate in a field test of the Computerized Adaptive Testing of the National Council Licensure Examination for Practical Nurses (NCLEX-PN). The experimental group for this study participated in the CAT simulation activity prior to taking NCLEX-PN and the control group did so after NCLEX-PN.    Both groups completed a 17 item Self-Report Anxiety Questionnaire. The responses were summed; the total score was considered to be a measure of anxiety.    Findings. Analysis of the data indicated that there was no statistically significant difference in computer test anxiety between the two groups. This is not to infer that there was no computer test anxiety expressed but rather that there was virtually no difference in the level of anxiety reported by the experimental group and the control group.    Further analysis of data indicated that persons with previous computer experience reported higher levels of computer test anxiety than those without previous computer experience and that females reported themselves as experiencing higher levels of computer test anxiety than did males. The results did not indicate that minorities experienced higher levels of computer test anxiety than non-minority groups. Lastly, there was no correlation between nursing grade point average or age and levels of computer test anxiety.    Conclusion. Participation in a computerized testing simulation did not affect the level of computer test anxiety. The only groups to experience higher levels of computer test anxiety are females and those with previous computer experience.
JF  - ProQuest Dissertations and Theses
AU  - Arrowood, Vada Ellis
A3  - Echternacht, Lonnie
Y1  - 1993
PY  - 1993
DA  - 1993
SP  - 127
CY  - United States -- Missouri
PB  - University of Missouri - Columbia
PP  - United States -- Missouri
SN  - 979-8-208-61100-5
KW  - Health and environmental sciences
KW  - Education
KW  - test anxiety
KW  - Educational evaluation
KW  - Educational psychology
KW  - Nursing licensure
KW  - Tests
KW  - Educational tests & measurements
KW  - Anxiety
KW  - Nursing
KW  - 0443:Educational evaluation
KW  - 0569:Nursing
KW  - 0525:Educational psychology
KW  - 0288:Educational tests & measurements
UR  - https://www.proquest.com/dissertations-theses/effects-computerized-adaptive-test-anxiety-on/docview/304041739/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=Effects+of+computerized+adaptive+test+anxiety+on+nursing+licensure+examination&issn=&date=1993-01-01&volume=&issue=&spage=&au=Arrowood%2C+Vada+Ellis&isbn=979-8-208-61100-5&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2022-10-29
M3  - Ed.D.
M1  - 9404945
ER  - 



TY  - RPRT
T1  - Test Anxiety and Test Performance Under Computerized Adaptive Testing Methods
AN  - 62934912; ED344910
AB  - Little research exists on the psychological impacts of computerized adaptive testing (CAT) and how it may affect test performance. Three CAT procedures were examined, in which items were selected to match students' achievement levels, from the item pool at random, or according to student choice of item difficulty levels. Twenty-four graduate students (5 males and 19 females) at Indiana University (Richmond) were randomly assigned to one of six testing orders formed by the three mastery test approaches and by blocking on native and non-native speakers. While at a computer, students received a description of adaptive testing methods and then a 20-item pre-test anxiety measure. Right after completing each test, students responded to a 10-item in-test anxiety scale, ranked their preferences among tests, and evaluated their performance on each of the tests. No statistically significant mean differences were found among mean student achievement scores or among in-test anxiety means under the three adaptive testing methods. Students reporting higher anxiety scored significantly higher in the matched-selection test. Those preferring the matched-selection and self-selection tests the most were less anxious during those tests. Instead of actual performance, students' perceptions of how well they did were significantly correlated with preference rankings for the tests. The matched-selection tests required significantly fewer items to reach decisions than did the random-selection tests. Ten tables, 1 figure, and a 19-item list of references are included. (Author/SLD)
AU  - Powell, Z. Emily
Y1  - 1992/04//
PY  - 1992
DA  - Apr 1992
SP  - 1
EP  - 34
KW  - Psychological Influences
KW  - Testing Effects
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Mastery Tests
KW  - Test Results
KW  - Scores
KW  - Student Attitudes
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Graduate Students
KW  - Computer Assisted Testing
KW  - Academic Achievement
KW  - Test Items
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/test-anxiety-performance-under-computerized/docview/62934912/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Test+Anxiety+and+Test+Performance+Under+Computerized+Adaptive+Testing+Methods&issn=&date=1992-04-01&volume=&issue=&spage=1&au=Powell%2C+Z.+Emily&isbn=&jtitle=&btitle=Test+Anxiety+and+Test+Performance+Under+Computerized+Adaptive+Testing+Methods&rft_id=info:eric/ED344910&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - How Review Options and Administration Modes Influence Scores on Computerized Vocabulary Tests
AN  - 62917480; ED346161
AB  - The effects of review options (the opportunity for examinees to review and change answers) on the magnitude, reliability, efficiency, and concurrent validity of scores obtained from three types of computerized vocabulary tests (fixed item, adaptive, and self-adapted) were studied. Subjects were 97 college students at a large midwestern university who each completed one of the vocabulary tests and several measures of attitudes about review, item difficulty, and test anxiety. Review modestly enhanced test performance, slightly decreased measurement precision, moderately increased total testing time, affected concurrent validity, and was strongly favored by examinees. Computerized tests do not necessarily yield equivalent results, and such tests may have to be equated to ensure fair use of test scores. Differences in performance favoring paper-and-pencil tests in some prior studies occurred because review options were excluded from the computerized tests. Results for administration mode are inconclusive. Compared to the other types, the fixed-item test yielded the least desirable results because scores were lowest, least reliable, and most susceptible to test anxiety effects. The choice between self-adapted and adaptive tests seems to depend on examinee anxiety level. Item difficulty suggestion, rather than answer feedback, is the predominant factor facilitating performance on self-adapted tests. Included are 3 tables, 4 graphs, and 38 references. (SLD)
AU  - Vispoel, Walter P.
AU  - And Others
Y1  - 1992/04//
PY  - 1992
DA  - Apr 1992
SP  - 1
EP  - 19
KW  - Fixed Item Tests
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Test Reliability
KW  - Scores
KW  - Error Correction
KW  - Concurrent Validity
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Test Wiseness
KW  - College Students
KW  - Feedback
KW  - Computer Assisted Testing
KW  - Review (Reexamination)
KW  - Difficulty Level
KW  - Test Anxiety
KW  - Vocabulary Skills
UR  - https://www.proquest.com/reports/how-review-options-administration-modes-influence/docview/62917480/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=How+Review+Options+and+Administration+Modes+Influence+Scores+on+Computerized+Vocabulary+Tests&issn=&date=1992-04-01&volume=&issue=&spage=1&au=Vispoel%2C+Walter+P.%3BAnd+Others&isbn=&jtitle=&btitle=How+Review+Options+and+Administration+Modes+Influence+Scores+on+Computerized+Vocabulary+Tests&rft_id=info:eric/ED346161&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - The Effects of Feedback in Computerized Adaptive and Self-Adapted Tests
AN  - 62836266; ED352391
AB  - Computerized adaptive (CA) testing uses an algorithm to match examinee ability to item difficulty, while self-adapted (SA) testing allows the examinee to choose the difficulty of his or her items. Research comparing SA and CA testing has shown that examinees experience lower anxiety and improved performance with SA testing. All previous research concerning SA testing has presented item feedback to the examinee before asking the examinee to choose the next item difficulty level. Moreover, item feedback has typically not been presented to examinees in previous CA testing research. The effects of presenting, versus withholding, item feedback in SA tests were studied for 135 graduate and 228 undergraduate students (128 males and 235 females). The instrument was a computerized algebra test to assess skills needed for a statistics class. Examinees administered the SA tests tended to obtain significantly higher ability estimates than did those who were administered the CA tests. Also, those taking the SA tests reported significantly lower post-test state anxiety than did those taking the CA tests. Interaction between test type and feedback was not found, suggesting that examinees are able to use the implicit feedback they receive when answering items. Five tables present study findings. (SLD)
AU  - Roos, Linda L.
AU  - And Others
Y1  - 1992/04//
PY  - 1992
DA  - Apr 1992
SP  - 1
EP  - 23
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Statistics
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Graduate Students
KW  - Ability Identification
KW  - Algebra
KW  - Algorithms
KW  - Feedback
KW  - Undergraduate Students
KW  - Computer Assisted Testing
KW  - Test Items
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/effects-feedback-computerized-adaptive-self/docview/62836266/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=The+Effects+of+Feedback+in+Computerized+Adaptive+and+Self-Adapted+Tests&issn=&date=1992-04-01&volume=&issue=&spage=1&au=Roos%2C+Linda+L.%3BAnd+Others&isbn=&jtitle=&btitle=The+Effects+of+Feedback+in+Computerized+Adaptive+and+Self-Adapted+Tests&rft_id=info:eric/ED352391&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - SuppNotes - Paper presented at the Annual Meeting of the National Council on Measurement in Education (San Francisco, CA, April 21-23, 1992).
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - A Comparison of Self-Adapted and Computerized Adaptive Tests
AN  - 62837396; EJ455219
AB  - Performance of 156 undergraduate and 48 graduate students on a self-adapted test (SFAT)--students choose the difficulty level of their test items--was compared with performance on a computer-adapted test (CAT). Those taking the SFAT obtained higher ability scores and reported lower posttest state anxiety than did CAT takers. (SLD)
JF  - Journal of Educational Measurement
AU  - Wise, Steven L.
AU  - And Others
Y1  - 1992///Jan 1992 - Mar
PY  - 1992
DA  - Jan 1992 - Mar 1992
SP  - 329
EP  - 39
VL  - 29
IS  - 4
SN  - 0022-0655, 0022-0655
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Higher Education
KW  - Estimation (Mathematics)
KW  - Scores
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Graduate Students
KW  - Test Construction
KW  - Test Format
KW  - Mathematics Tests
KW  - Undergraduate Students
KW  - Computer Assisted Testing
KW  - Multiple Choice Tests
KW  - Test Items
KW  - Difficulty Level
KW  - Item Response Theory
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/comparison-self-adapted-computerized-adaptive/docview/62837396/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=A+Comparison+of+Self-Adapted+and+Computerized+Adaptive+Tests&title=Journal+of+Educational+Measurement&issn=00220655&date=1992-01-01&volume=29&issue=4&spage=329&au=Wise%2C+Steven+L.%3BAnd+Others&isbn=&jtitle=Journal+of+Educational+Measurement&btitle=&rft_id=info:eric/EJ455219&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - Adaptive Testing 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; Comparative Testing 1987ER1 10919ER1 6526ER1 6663ER1 1973ER5 10827ER5 6467ER5 6603ER5; Computer Assisted Testing 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2883ER1 2862ER5; Estimation (Mathematics); Graduate Students 4514ER1 1829ER1 10411ER1 8114ER1 4605ER1 4467ER5 1815ER5 10321ER5 8043ER5 4558ER5; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5; 5598ER1 10914ER1 10966ER1 5545ER5 10822ER5 10874ER5; 6503ER1 10925ER1 6527ER1 6444ER5 10833ER5 6468ER5; 6957ER1 7318ER1 10925ER1 6527ER1 6894ER5 7254ER5 10833ER5 6468ER5; 9485ER1 2602ER1 9404ER5 2584ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10895ER1 6468ER1 2820ER1 10803ER5 6409ER5 2799ER5; Test Format 10898ER1 10806ER5; 10900ER1 10808ER5; Undergraduate Students 11231ER1 1829ER1 10411ER1 8114ER1 4605ER1 11139ER5 1815ER5 10321ER5 8043ER5 4558ER5
ER  - 



TY  - THES
T1  - The effect of adaptive testing item selection methods on the precision of ability estimation and the examinee's motivation
AN  - 304000167
AB  - Item selection is very important in the computerized adaptive testing (CAT) since each item is critical in determining the precision of ability estimation and the examinee's motivation in taking the test. The precision of ability estimation can be enhanced by maximizing item information, and the examinee's motivation is most influenced by the item difficulty.    The matching $m\sb{j}$ to $\\theta$ item selection (Matching) method selects easier items but does not maximize information. The maximum information item selection (Maxinfo) method sometimes selects items which are too difficult for the examinees. The purpose of the study is to explore the maximum information of an adjusted $\\theta$ item selection (Adjusted) method which is designed to combine the above two methods to select easier items but yet to maximize information. These item selection methods are different in terms of the difficulty and information of the items selected. They were compared in the modified microcomputerized adaptive placement test in mathematics (MAPTM-1) system which employs the EAP (Expected A Posteriori) scoring method. One hundred and thirty-five paid subjects were stratified into the low, medium, and high math levels. Within each math level, subjects were randomly assigned to be tested using one of the three methods. A further simulation study of the methods was based on data generated from the real data.    Matching did not perform as well as the other two methods. Adjusted tended to select higher discriminating and easier items than Maxinfo in medium and high math levels; in simulation, the differences in the characteristics of items selected between Adjusted and Maxinfo vanished. Maxinfo and Adjusted were about the same in terms of information and posterior standard deviation of the ability estimate; they were more precise than Matching. It is very promising that Adjusted can replace Maxinfo. There was no significant difference among the methods in the analyses of the examinees' motivation levels. However, the difficulty of the test may still have had an effect on the examinees' motivation if the test was administered to examinees who were required to take it for placement purpose.
JF  - ProQuest Dissertations and Theses
AU  - Jeng, Hi-Lian
A3  - Hsu, Tse-chi
Y1  - 1992
PY  - 1992
DA  - 1992
SP  - 187
CY  - United States -- Pennsylvania
PB  - University of Pittsburgh
PP  - United States -- Pennsylvania
SN  - 979-8-209-32746-2
KW  - Education
KW  - Psychology
KW  - CAT
KW  - Educational evaluation
KW  - Educational psychology
KW  - Psychological tests
KW  - Educational technology
KW  - 0632:Quantitative psychology
KW  - 0710:Educational technology
KW  - 0525:Educational psychology
KW  - 0288:Educational tests & measurements
UR  - https://www.proquest.com/dissertations-theses/effect-adaptive-testing-item-selection-methods-on/docview/304000167/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=The+effect+of+adaptive+testing+item+selection+methods+on+the+precision+of+ability+estimation+and+the+examinee%27s+motivation&issn=&date=1992-01-01&volume=&issue=&spage=&au=Jeng%2C+Hi-Lian&isbn=979-8-209-32746-2&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2022-03-01
M3  - Ph.D.
M1  - 9319168
ER  - 



TY  - JOUR
T1  - Correlates of Examinee Item Choice Behavior in Self-Adapted Testing
AN  - 63021707; EJ429116
AB  - Among 148 college students taking a self-adapted computerized test of basic algebra skills, higher self-confidence and lower test anxiety were related to choosing more difficult first items but were not related to later choices. Overall, examinees chose items of moderate difficulty relative to their ability level. (SV)
JF  - Mid-Western Educational Researcher
AU  - Johnson, Phillip L.
AU  - And Others
Y1  - 1991///Jul 1991 - Sep
PY  - 1991
DA  - Jul 1991 - Sep 1991
SP  - 25
EP  - 28
VL  - 4
IS  - 3
KW  - Self Adapted Testing
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Higher Education
KW  - Test Wiseness
KW  - College Students
KW  - Academic Ability
KW  - Computer Assisted Testing
KW  - Response Style (Tests)
KW  - Student Behavior
KW  - Self Esteem
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/correlates-examinee-item-choice-behavior-self/docview/63021707/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Correlates+of+Examinee+Item+Choice+Behavior+in+Self-Adapted+Testing&title=Mid-Western+Educational+Researcher&issn=&date=1991-07-01&volume=4&issue=3&spage=25&au=Johnson%2C+Phillip+L.%3BAnd+Others&isbn=&jtitle=Mid-Western+Educational+Researcher&btitle=&rft_id=info:eric/EJ429116&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 27ER1 2ER1 26ER5 1ER5; 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1829ER1 10411ER1 8114ER1 4605ER1 1815ER5 10321ER5 8043ER5 4558ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5; 9039ER1 921ER1 8959ER5 912ER5; 9584ER1 9566ER1 9503ER5 9485ER5; 10311ER1 921ER1 10221ER5 912ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10918ER1 10826ER5
ER  - 



TY  - RPRT
T1  - Correlates of Examinee Item Choice Behavior in Self-Adapted Testing
AN  - 63001252; ED331889
AB  - The strategies examinees employ when making item difficulty level choices in self-adapted computerized testing were investigated. Subjects were 148 college students (88 females and 60 males) in an introductory statistics course. The primary instrument was a self-adapted computerized algebra test used to measure student readiness for the statistics course. Each examinee was administered 20 items from a pool of 93. Students rated their self-efficacy before the test and were administered measures of mathematics anxiety and test anxiety. Inspection of each student's data file provided an indicator of selection strategy. Examinees who chose a more difficult first test item expressed greater capability and higher confidence, reported less anxiety just prior to testing, and less anxiety about mathematics in general. When selecting additional items, examinees tended toward what was termed a sluggishly flexible strategy; they chose more difficult items after passing an item or string of items, and chose less difficult items after failing a single item or string of items. The most frequent choice was to remain at the same level. Results indicate that self-adaptive testing may be a viable alternative to computerized adaptive testing. Two figures and two tables contain data from the study. (SLD)
AU  - Johnson, Phillip L.
AU  - And Others
Y1  - 1991/04//
PY  - 1991
DA  - Apr 1991
SP  - 1
EP  - 15
KW  - Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Correlation
KW  - Higher Education
KW  - Self Efficacy
KW  - Statistics
KW  - Adaptive Testing
KW  - Mathematics Anxiety
KW  - Test Construction
KW  - Algebra
KW  - College Students
KW  - Mathematics Tests
KW  - Computer Assisted Testing
KW  - Item Banks
KW  - Test Items
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/correlates-examinee-item-choice-behavior-self/docview/63001252/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Correlates+of+Examinee+Item+Choice+Behavior+in+Self-Adapted+Testing&issn=&date=1991-04-01&volume=&issue=&spage=1&au=Johnson%2C+Phillip+L.%3BAnd+Others&isbn=&jtitle=&btitle=Correlates+of+Examinee+Item+Choice+Behavior+in+Self-Adapted+Testing&rft_id=info:eric/ED331889&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - A Comparison of Self-Adapted and Computer-Adaptive Tests
AN  - 63001134; ED331888
AB  - According to item response theory (IRT), examinee ability estimation is independent of the particular set of test items administered from a calibrated pool. Although the most popular application of this feature of IRT is computerized adaptive (CA) testing, a recently proposed alternative is self-adapted (SA) testing, in which examinees choose the difficulty level of each of their test items. Examinee performance was compared under CA and SA testing conditions for college students from an introductory statistics course. Three test forms were developed, testing mathematical knowledge necessary for the course. The final pool contained 93 items which were administered to 204 subjects. The SA test yielded significantly higher ability scores, and examinees taking the SA test reported significantly lower posttest state anxiety. Implications of the differences between the two test types for measurement practice are discussed. Three tables present study data. (Author/SLD)
AU  - Wise, Steven L.
AU  - And Others
Y1  - 1991/04//
PY  - 1991
DA  - Apr 1991
SP  - 1
EP  - 20
KW  - Self Adapted Testing
KW  - ERIC, Resources in Education (RIE)
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Ability Identification
KW  - Higher Education
KW  - College Students
KW  - Computer Assisted Testing
KW  - Item Banks
KW  - Difficulty Level
KW  - Statistics
KW  - Item Response Theory
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/comparison-self-adapted-computer-adaptive-tests/docview/63001134/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=A+Comparison+of+Self-Adapted+and+Computer-Adaptive+Tests&issn=&date=1991-04-01&volume=&issue=&spage=1&au=Wise%2C+Steven+L.%3BAnd+Others&isbn=&jtitle=&btitle=A+Comparison+of+Self-Adapted+and+Computer-Adaptive+Tests&rft_id=info:eric/ED331888&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - Individual Differences in Computer Adaptive Testing: Anxiety, Computer Literacy and Satisfaction
AN  - 62563471; ED400285
AB  - The relationship of several individual differences variables to Computer Adaptive Testing (CAT) as compared with traditional written tests are explored. Seven hundred sixty-five examinees took a Computer Adaptive Test and two fixed-length written tests. Each examinee also answered a computer literacy inventory, a satisfaction questionnaire, and a test anxiety survey. Test anxiety was found to be a significant factor in performance on both of the written tests, but not on the CAT test. Anxiety was also found to be a significant factor on several of the items on the satisfaction questionnaire. Overall, significant factors that predict satisfaction with CAT testing included level of test anxiety, computer literacy, and test length (the CAT test varied in terms of the number of items administered). Results are discussed in terms of the political and practical implications of administering CAT tests as compared to administering traditional written tests. The results also indicate that some of the individual differences variables that have been found to affect performance on written tests are not significant in CAT. (Contains two tables and six references.) (Author/SLD)
AU  - Gershon, Richard C.
AU  - Bergstrom, Betty
Y1  - 1991/04//
PY  - 1991
DA  - Apr 1991
SP  - 1
EP  - 18
KW  - ERIC, Resources in Education (RIE)
KW  - Adaptive Testing
KW  - Test Length
KW  - Computer Assisted Testing
KW  - Satisfaction
KW  - Adults
KW  - Computer Literacy
KW  - Individual Differences
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/individual-differences-computer-adaptive-testing/docview/62563471/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Individual+Differences+in+Computer+Adaptive+Testing%3A+Anxiety%2C+Computer+Literacy+and+Satisfaction&issn=&date=1991-04-01&volume=&issue=&spage=1&au=Gershon%2C+Richard+C.%3BBergstrom%2C+Betty&isbn=&jtitle=&btitle=Individual+Differences+in+Computer+Adaptive+Testing%3A+Anxiety%2C+Computer+Literacy+and+Satisfaction&rft_id=info:eric/ED400285&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - SuppNotes - Paper presented at the Annual Meeting of the National Council on Measurement in Education (San Francisco, CA, April 21-23, 1991).
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - The Effects of Computer-Based Pretesting Strategies on Learning and Continuing Motivation
AN  - 62919344; EJ443394
AB  - Fifth and sixth grade children were assigned to three pretesting conditions: a full-length pretest, an adaptive pretest that exited learners when nonmastery was indicated, and a no pretest control. Learners in the adaptive treatment demonstrated higher levels of performance on the posttest and had greater motivation to continue the instruction. (24 references) (DB)
JF  - Journal of Research on Computing in Education
AU  - Dalton, David W.
AU  - Goodrum, David A.
Y1  - 1991///Jan 1991 - Mar
PY  - 1991
DA  - Jan 1991 - Mar 1991
SP  - 204
EP  - 13
VL  - 24
IS  - 2
SN  - 0888-6504, 0888-6504
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Grade 5
KW  - Grade 6
KW  - Computer Assisted Testing
KW  - Academic Achievement
KW  - Intermode Differences
KW  - Elementary Education
KW  - Pretests Posttests
UR  - https://www.proquest.com/scholarly-journals/effects-computer-based-pretesting-strategies-on/docview/62919344/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=The+Effects+of+Computer-Based+Pretesting+Strategies+on+Learning+and+Continuing+Motivation&title=Journal+of+Research+on+Computing+in+Education&issn=08886504&date=1991-01-01&volume=24&issue=2&spage=204&au=Dalton%2C+David+W.%3BGoodrum%2C+David+A.&isbn=&jtitle=Journal+of+Research+on+Computing+in+Education&btitle=&rft_id=info:eric/EJ443394&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 29ER1 98ER1 28ER5 96ER5; Adaptive Testing 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; Computer Assisted Testing 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 3396ER1 3412ER1 3192ER1 3366ER5 3382ER5 3164ER5; 4484ER1 5331ER1 4437ER5 5281ER5; 4485ER1 5331ER1 4438ER5 5281ER5; Intermode Differences 5469ER1 2875ER1 5418ER5 2854ER5; Pretests Posttests 8269ER1 10925ER1 6527ER1 8195ER5 10833ER5 6468ER5; Student Motivation 10358ER1 6915ER1 10268ER5 6852ER5
ER  - 



TY  - THES
T1  - Test anxiety and test performance under computerized adaptive testing methods
AN  - 303923651
AB  - Research on computerized adaptive testing (CAT) has shown its potential to estimate student achievement accurately and efficiently. However, there is a paucity of research on the psychological impacts of CAT and how it may, consequently, affect test performance. Three kinds of computerized adaptive testing procedures were examined, in which items were selected in one of three ways: (a) to match students' estimated achievement levels (matched-selection), (b) from the item pool at random (random-selection), and (c) according to student choice of item difficulty levels (self-selection).    Twenty-four graduate students were randomly assigned to one of six possible testing orders formed by the three adaptive tests while blocking on native and nonnative speakers. While at a computer, students first received a description of adaptive testing methods, followed by a 20-item pre-test anxiety measure. The three adaptive tests were then given in the assigned random order. Immediately after each adaptive test, students responded to a 10-item in-test anxiety scale. Finally, they ranked their preferences and evaluated their performance on each of the three tests. Written student comments and questions regarding the adaptive testing methods were also solicited.    No statistically significant differences were found among mean student achievement scores, nor among in-test anxiety means, under the three adaptive testing methods. Students who reported higher pre-test anxiety were found to score significantly higher in the matched-selection test. Students who preferred the matched-selection and self-selection tests the most tended to be significantly less anxious during those tests. However, instead of students' actual test performance, it was their perception of how well they did that was significantly correlated with their preference rankings for the three tests. Though not central to this study, the matched-selection tests required significantly fewer items to reach mastery decisions than did the random-selection tests.
JF  - ProQuest Dissertations and Theses
AU  - Powell, Zen-Hsiu Emily
Y1  - 1991
PY  - 1991
DA  - 1991
SP  - 179
CY  - United States -- Indiana
PB  - Indiana University
PP  - United States -- Indiana
SN  - 979-8-207-01213-1
KW  - Education
KW  - Educational evaluation
KW  - Curricula
KW  - Teaching
KW  - Educational technology
KW  - 0727:Curriculum development
KW  - 0710:Educational technology
KW  - 0288:Educational tests & measurements
UR  - https://www.proquest.com/dissertations-theses/test-anxiety-performance-under-computerized/docview/303923651/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&genre=dissertations&sid=ProQ:ProQuest+Dissertations+%26+Theses+Global&atitle=&title=Test+anxiety+and+test+performance+under+computerized+adaptive+testing+methods&issn=&date=1991-01-01&volume=&issue=&spage=&au=Powell%2C+Zen-Hsiu+Emily&isbn=979-8-207-01213-1&jtitle=&btitle=&rft_id=info:eric/&rft_id=info:doi/
LA  - English
DB  - ProQuest Dissertations & Theses Global
N1  - Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.
N1  - Zuletzt aktualisiert - 2022-11-23
M3  - Ph.D.
M1  - 9134822
ER  - 



TY  - RPRT
T1  - Investigating Differences in Mean Score on Adaptive and Paper and Pencil Versions of the College Level Academic Skills Reading Test
AN  - 63059154; ED319791
AB  - Possible causes of a 16-point mean score increase for the computer adaptive form of the College Level Academic Skills Test (CLAST) in reading over the paper-and-pencil test (PPT) in reading are examined. The adaptive form of the CLAST was used in a state-wide field test in which reading, writing, and computation scores for approximately 1,000 students were compared for the March or June 1988 administrations of the PPT and the spring of 1988 administration of the computer adaptive test (CAT) version. The field study data were analyzed to address measurement error, content coverage and reading load, and student motivation. A follow-up study used data from 361 community college freshmen and sophomore students who had taken the October 1989 or March 1990 paper-and-pencil version of the CLAST but had not yet received their scores; these subjects were administered the Nelson-Denny Reading Test, as well as the CAT form of the CLAST. The follow-up study failed to replicate the difference in mean scores for the computer adaptive and paper-and-pencil versions of the reading test that were found in the preliminary analysis. Overall results indicate that students should be allowed a longer testing period for the CAT version of the CLAST than for the PPT version. Seven data tables are included. (TJH)
AU  - Legg, Sue M.
AU  - Buhr, Dianne C.
Y1  - 1990/04//
PY  - 1990
DA  - Apr 1990
SP  - 1
EP  - 12
KW  - College Level Academic Skills Test
KW  - Paper and Pencil Tests
KW  - ERIC, Resources in Education (RIE)
KW  - Followup Studies
KW  - Higher Education
KW  - Error of Measurement
KW  - Timed Tests
KW  - Reading Tests
KW  - Scores
KW  - College Entrance Examinations
KW  - Community Colleges
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Student Motivation
KW  - Test Format
KW  - Undergraduate Students
KW  - Computer Assisted Testing
KW  - Field Studies
UR  - https://www.proquest.com/reports/investigating-differences-mean-score-on-adaptive/docview/63059154/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Investigating+Differences+in+Mean+Score+on+Adaptive+and+Paper+and+Pencil+Versions+of+the+College+Level+Academic+Skills+Reading+Test&issn=&date=1990-04-01&volume=&issue=&spage=1&au=Legg%2C+Sue+M.%3BBuhr%2C+Dianne+C.&isbn=&jtitle=&btitle=Investigating+Differences+in+Mean+Score+on+Adaptive+and+Paper+and+Pencil+Versions+of+the+College+Level+Academic+Skills+Reading+Test&rft_id=info:eric/ED319791&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - Test Anxiety and Item Order: New Parameters for Item Response Theory
AN  - 63129829; ED307313
AB  - Examinees (N=1,233) at the Johnson O'Connor Research Foundation (JOCRF) were administered one of three test forms in which only item order differed. The study was undertaken to determine the validity of the assumption underlying item response theory (IRT) that there are fixed item parameters that can predict performance. The Rasch IRT model was chosen. The three experimental tests were constructed from 950 items found in the JOCRF's item bank. The population seen at the JOCRF ranges in age from 14 to 60 years. Personality tests administered to subjects included Mandler and Sarason's Test Anxiety Scale and a short series of test-taking strategy items. All subjects took a minimum of 18 aptitude tests. Three primary factors were included in the analyses: (1) level of test anxiety; (2) ability; and (3) difficulty order. Results of the study indicate that item difficulty order, test anxiety, and ability all affect performance, violating assumptions of IRT. It appears that the theory neglects to address the effects of individual differences on test behavior. Adaptive testing techniques are reviewed, and the theories of test anxiety and associated measurement instruments are discussed. New testing strategies are proposed in which personality variables and test characteristics can be incorporated as parameters, allowing tests to be manipulated in a manner that maximizes performance. Three tables and nine graphs present study data. A 55-item list of references is provided. (TJH)
AU  - Gershon, Richard C.
Y1  - 1989/03//
PY  - 1989
DA  - Mar 1989
SP  - 1
EP  - 29
KW  - Johnson O Connor Aptitude Tests
KW  - Rasch Model
KW  - Item Position (Tests)
KW  - ERIC, Resources in Education (RIE)
KW  - Academic Ability
KW  - Personality Measures
KW  - Adaptive Testing
KW  - Comparative Analysis
KW  - Personality Traits
KW  - Latent Trait Theory
KW  - Aptitude Tests
KW  - Adults
KW  - Predictive Validity
KW  - Adolescents
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/test-anxiety-item-order-new-parameters-response/docview/63129829/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Test+Anxiety+and+Item+Order%3A+New+Parameters+for+Item+Response+Theory&issn=&date=1989-03-01&volume=&issue=&spage=1&au=Gershon%2C+Richard+C.&isbn=&jtitle=&btitle=Test+Anxiety+and+Item+Order%3A+New+Parameters+for+Item+Response+Theory&rft_id=info:eric/ED307313&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - Individual Differences in Item Selection in Computerized Self Adapted Testing
AN  - 63023394; ED310136
AB  - In self-adapted testing, examinees are allowed to choose the difficulty of each item to be presented immediately before attempting it. Previous research has demonstrated that self-adapted testing leads to better performance than do fixed-order tests and is preferred by examinees. The present study examined the strategies that 29 college students used in selecting items during a self-adapted test. After completing the Test Anxiety Inventory, subjects took the self-adapted test. The test contained 40 items sorted into 8 categories of difficulty based on Rasch model estimates. Three test-taking strategies were identified. Most subjects adopted a flexible strategy in which they generally selected easier items following failure and harder items following success. Some subjects adopted a "failure intolerant" strategy in which they generally selected easier items following failure and items of the same difficulty after success. Finally, some subjects adopted a "failure tolerant" strategy in which they chose items of the same difficulty level after failure, but harder items after success. The failure-tolerant strategy was associated with lower estimated ability than were the other two strategies. This finding may reflect the attributions examinees adopting that strategy make and the effort they expend following failures. The results provide general support for the value of continued development of self-adapted testing. (Author/TJH)
AU  - Rocklin, Thomas
Y1  - 1989/03//
PY  - 1989
DA  - Mar 1989
SP  - 1
EP  - 15
KW  - Test Anxiety Inventory
KW  - Self Adapted Testing
KW  - Test Anxiety Inventory (Spielberger)
KW  - Preference Patterns
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Individual Differences
KW  - Success
KW  - Adaptive Testing
KW  - Attribution Theory
KW  - Test Wiseness
KW  - College Students
KW  - Computer Assisted Testing
KW  - Test Items
KW  - Difficulty Level
KW  - Failure
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/individual-differences-item-selection/docview/63023394/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Individual+Differences+in+Item+Selection+in+Computerized+Self+Adapted+Testing&issn=&date=1989-03-01&volume=&issue=&spage=1&au=Rocklin%2C+Thomas&isbn=&jtitle=&btitle=Individual+Differences+in+Item+Selection+in+Computerized+Self+Adapted+Testing&rft_id=info:eric/ED310136&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - JOUR
T1  - Self-Adapted Testing: A Performance-Improving Variant of Computerized Adaptive Testing
AN  - 63173886; EJ364450
AB  - An experiment was conducted that contrasted a variant of computerized adaptive testing, self-adapted testing, with two traditional tests. Participants completed a self-report of text anxiety and were randomly assigned to take one of the three tests of verbal ability. Subjects generally chose more difficult items as the test progressed. (Author/LMO)
JF  - Journal of Educational Psychology
AU  - Rocklin, Thomas
AU  - O'Donnell, Angela M.
Y1  - 1987/09//
PY  - 1987
DA  - Sep 1987
SP  - 315
EP  - 19
VL  - 79
IS  - 3
KW  - Test Anxiety Inventory
KW  - Self Adapted Tests
KW  - Test Anxiety Inventory (Spielberger)
KW  - ERIC, Current Index to Journals in Education (CIJE)
KW  - Adaptive Testing
KW  - Comparative Testing
KW  - Higher Education
KW  - Computer Assisted Testing
KW  - Verbal Tests
KW  - Test Items
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/scholarly-journals/self-adapted-testing-performance-improving/docview/63173886/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=article&sid=ProQ:ProQ%3Aeric&atitle=Self-Adapted+Testing%3A+A+Performance-Improving+Variant+of+Computerized+Adaptive+Testing&title=Journal+of+Educational+Psychology&issn=&date=1987-09-01&volume=79&issue=3&spage=315&au=Rocklin%2C+Thomas%3BO%27Donnell%2C+Angela+M.&isbn=&jtitle=Journal+of+Educational+Psychology&btitle=&rft_id=info:eric/EJ364450&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - SubjectsTermNotLitGenreText - 140ER1 10919ER1 6526ER1 6663ER1 138ER5 10827ER5 6467ER5 6603ER5; 1987ER1 10919ER1 6526ER1 6663ER1 1973ER5 10827ER5 6467ER5 6603ER5; 2043ER1 2099ER1 2098ER1 10811ER1 10919ER1 6526ER1 6663ER1 2029ER5 2085ER5 2084ER5 10719ER5 10827ER5 6467ER5 6603ER5; 2883ER1 2862ER5; 4809ER1 8147ER1 3192ER1 4761ER5 8075ER5 3164ER5; 10890ER1 554ER1 8522ER1 10798ER5 549ER5 8446ER5; 10900ER1 10808ER5; 11371ER1 10925ER1 6527ER1 11279ER5 10833ER5 6468ER5
ER  - 



TY  - RPRT
T1  - Interactive Computer Administration of a Spatial Reasoning Test. Research Report 80-2
AN  - 63605265; ED191892
AB  - A pilot study on the development and administration of a test using a spatial reasoning problem, the 15-puzzle, is described. The test utilizes on-line capabilities of a real-time computer to record an examinee's progress on each problem through a sequence of problem-solving "moves", and to collect additional on-line data that might be of relevance to the evaluation of examinee performance. The examinees, 61 students in an introductory psychology class, were required to type a sequence of moves that would bring an array of scrambled numbers (start configuration) into agreement with a second array (goal configuration), using as few moves as possible. Results suggest that four performance indices might be useful in indexing problem difficulty: (1) mean number of moves in the sample; (2) proportion of students solving the problem; (3) proportion of students solving the problem in the optimal number of moves; and (4) a Special Difficulty Index, defined as the sample mean number of moves divided by the minimum number of moves required. Additional methods of scoring test and individual problem performance are studied. (Author/RL)
AU  - Church, Austin T.
AU  - Weiss, David J.
Y1  - 1980/04//
PY  - 1980
DA  - Apr 1980
SP  - 1
EP  - 87
KW  - Response Patterns
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Test Reliability
KW  - Memory
KW  - Cognitive Measurement
KW  - Problem Solving
KW  - Psychometrics
KW  - Reaction Time
KW  - Individual Differences
KW  - Adaptive Testing
KW  - Spatial Ability
KW  - Student Motivation
KW  - Test Construction
KW  - Testing Problems
KW  - Computer Assisted Testing
KW  - Scoring Formulas
KW  - Test Interpretation
KW  - Difficulty Level
UR  - https://www.proquest.com/reports/interactive-computer-administration-spatial/docview/63605265/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=Interactive+Computer+Administration+of+a+Spatial+Reasoning+Test.+Research+Report+80-2&issn=&date=1980-04-01&volume=&issue=&spage=1&au=Church%2C+Austin+T.%3BWeiss%2C+David+J.&isbn=&jtitle=&btitle=Interactive+Computer+Administration+of+a+Spatial+Reasoning+Test.+Research+Report+80-2&rft_id=info:eric/ED191892&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



TY  - RPRT
T1  - The Effects of Knowledge of Results and Test Difficulty on Ability Test Performance and Psychological Reactions to Testing. Research Report 78-2
AN  - 63755844; ED166232
AB  - Volunteer college students were assigned to one of six computer administered vocabulary tests, one half with immediate knowledge of results (KR) after responding to each item, and the other half without knowledge of results. The six tests were designed to be at one of three levels of difficulty and consisted either of 50 preselected items (conventional testing) or tailored on the basis of previous candidate responses (stradaptive testing). Results indicated that the mean maximum-likelihood estimates of individuals' ability varied as a joint function of the KR condition and of test difficulty. Students in the KR condition scored higher than the other students on the most difficult test and lower on the least difficult test. Questionnaire results indicated that, although the students perceived the differences in test difficulty, there were not shown to be any effects on mean student anxiety or motivation scores attributable to test difficulty alone. Students in general reacted very favorably to receiving immediate knowledge of results and its provision increased the mean level of reported motivation. (Author/CTM)
AU  - Prestwood, J. Stephen
AU  - Weiss, David J.
Y1  - 1978/09//
PY  - 1978
DA  - Sep 1978
SP  - 1
EP  - 31
PB  - Psychometric Methods Program
KW  - ERIC, Resources in Education (RIE)
KW  - Higher Education
KW  - Student Characteristics
KW  - Academic Ability
KW  - Verbal Tests
KW  - Adaptive Testing
KW  - Student Motivation
KW  - Feedback
KW  - Computer Assisted Testing
KW  - Student Reaction
KW  - Anxiety
KW  - Item Analysis
KW  - Test Items
KW  - Difficulty Level
KW  - Test Anxiety
UR  - https://www.proquest.com/reports/effects-knowledge-results-test-difficulty-on/docview/63755844/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:book&genre=report&sid=ProQ:ProQ%3Aeric&atitle=&title=The+Effects+of+Knowledge+of+Results+and+Test+Difficulty+on+Ability+Test+Performance+and+Psychological+Reactions+to+Testing.+Research+Report+78-2&issn=&date=1978-09-01&volume=&issue=&spage=1&au=Prestwood%2C+J.+Stephen%3BWeiss%2C+David+J.&isbn=&jtitle=&btitle=The+Effects+of+Knowledge+of+Results+and+Test+Difficulty+on+Ability+Test+Performance+and+Psychological+Reactions+to+Testing.+Research+Report+78-2&rft_id=info:eric/ED166232&rft_id=info:doi/
LA  - English
DB  - ERIC
N1  - SuppNotes - Parts marginally legible due to print quality
N1  - Zuletzt aktualisiert - 2021-02-11
N1  - Vertragsnummer - N00014-76-C-0243
ER  - 



TY  - GEN
T1  - Testing and the Public Interest
AN  - 63833992; ED150191
AB  - The 1976 Educational Testing Service (ETS) Invitational Conference served as a platform for individuals who have been prominent in educational measurement and research to present their views on issues surrounding the testing controversy. The 1976 ETS "The Testing Scene: Chaos and Controversy," presents a historical review of events surrounding the testing controversy. In "Test Theory and the Public Interest," Frederic M. Lord suggested three alternatives for solving some of the problems of cultural test bias: weighted scoring techniques, tailored testing, and item sampling. Esther E. Diamond discussed test construction techniques that could alleviate bias, in "Testing: The Baby and the Bath Water Are Still With Us." In "One Man's View of Testing," William Raspberry stated that norming contributes to cultural bias. Thelma T. Daley discussed the effects of testing on students, in "The Student and Testing." In the final paper, "Where Ignorance Is Bliss--'Tis Folly to be Testing," Robert L. Thorndike recommended that tests be evaluated in light of the decisions that will be based upon their results. (BW)
Y1  - 1977
PY  - 1977
DA  - 1977
SP  - 1
EP  - 82
PB  - Invitational Conference
KW  - ERIC, Resources in Education (RIE)
KW  - Disadvantaged
KW  - Achievement Tests
KW  - Scores
KW  - Student Attitudes
KW  - Test Validity
KW  - Criterion Referenced Tests
KW  - Test Bias
KW  - Culture Fair Tests
KW  - Item Sampling
KW  - Performance Factors
KW  - Test Construction
KW  - Educational Assessment
KW  - Testing Problems
KW  - Racial Discrimination
KW  - Low Ability Students
KW  - Test Interpretation
KW  - Competitive Selection
KW  - Norm Referenced Tests
KW  - Conference Reports
KW  - Test Anxiety
KW  - Minority Groups
KW  - Test Theory
KW  - Higher Education
KW  - Educational Testing
KW  - Test Reliability
KW  - Adaptive Testing
KW  - Elementary Secondary Education
KW  - Awards
KW  - Sex Discrimination
KW  - Standardized Tests
KW  - Career Development
KW  - Disadvantaged
KW  - Achievement Tests
KW  - Scores
KW  - Student Attitudes
KW  - Test Validity
KW  - Criterion Referenced Tests
KW  - Test Bias
KW  - Culture Fair Tests
KW  - Item Sampling
KW  - Performance Factors
KW  - Test Construction
KW  - Educational Assessment
KW  - Testing Problems
KW  - Racial Discrimination
KW  - Low Ability Students
KW  - Test Interpretation
KW  - Competitive Selection
KW  - Norm Referenced Tests
KW  - Conference Reports
KW  - Test Anxiety
KW  - Minority Groups
KW  - Test Theory
KW  - Higher Education
KW  - Educational Testing
KW  - Test Reliability
KW  - Adaptive Testing
KW  - Elementary Secondary Education
KW  - Awards
KW  - Sex Discrimination
KW  - Standardized Tests
KW  - Career Development
UR  - https://www.proquest.com/conference-papers-proceedings/testing-public-interest/docview/63833992/se-2?accountid=10957
L2  - http://www.redi-bw.de/links/unifm?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&genre=proceeding&sid=ProQ:ProQ%3Aeric&atitle=Testing+and+the+Public+Interest&title=Undefined&issn=&date=1977-01-01&volume=&issue=&spage=1&au=&isbn=&jtitle=Undefined&btitle=&rft_id=info:eric/ED150191&rft_id=info:doi/
LA  - Undefined
DB  - ERIC
N1  - Zuletzt aktualisiert - 2021-02-11
ER  - 



